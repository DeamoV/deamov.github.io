<?xml version="1.0" encoding="utf-8"?>
<search>
  
    <entry>
      <title><![CDATA[Tensorflowjs Playground]]></title>
      <url>/fewshotlearning/2020/02/16/tensorflowjs/</url>
      <content type="text"><![CDATA[                       Try to train mnit with official code      Train a model to recognize handwritten digits from the MNIST database using the tf.layers        api.                    Description            This test show the awesome feature for tfjs. We will used trained model later. The MNIST dataset is used as training data.                     Give it a try             Choose which model (                  ConvNet          DenseNet              ) to use and train  epochs.            Load Data and Train Model              Training Progress                                                                                                          ]]></content>
      <categories>
        
          <category> FewShotLearning </category>
        
      </categories>
      <tags>
        
          <tag> Few_Shot_Learning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Get To The Point: Summarization with Pointer-Generator Networks论文笔记]]></title>
      <url>/nlp/2019/04/04/Get_To_The_Point_Summarization_with_Pointer-Generator_Networks_review/</url>
      <content type="text"><![CDATA[﻿### 论文：Get To The Point: Summarization with Pointer-Generator Networks解读Abstract类型的文本摘要存在的问题：  容易产生不准确的事实；  倾向于重复相同的内容。注：如上面所示，作为基线的seq2seq+Attention这样的纯粹的生成式模型存在1.无法生成OOV词汇；2.歪曲事实两个问题。Pointer Generator 存在重复内容的问题。在引入Coverage mechanism之后的Pointer-Gen+Coverage模型能够解决上面的三个问题。论文的创新点：  （1）使用一个混合的指针-生成器网络(hybrid pointer-generator network)，它可以通过指针从源文本复制单词，这有助于准确复制信息，同时保留通过生成器生成新单词的能力。  （2）使用覆盖率（coverage）来追踪摘要的内容，这有助于缓解重复的现象。Introduction​	文本摘要使用抽取和生成两种方法：抽取式和生成式。抽取式是从文章中选择关键的词句拼接而成，这种方式能够保证生成句子语法和准确性的下限。然而高质量的摘要往往需要分段、泛化或者结合知识，这种类型的摘要只能使用生成式方法。seq2seq模型有三个问题：不准确的再现事实，无法处理词汇表外的（OOV）的单词，重复自己。论文提出的模型可以在多句子的文本摘要中解决这三个问题。混合指针-生成器网络便于通过指向从源文本复制单词，这提高了OOV单词的准确性和处理能力，同时保留了生成新单词的能力。可以看作是提取和抽象方法之间的平衡。在消除重复方面，论文提出了覆盖向量（coverage vector）来跟踪和控制对源文本的覆盖。seq2seq attention model1.标准的seq2seq模型使用BiLSTM对源文本进行编码，然后使用Encoder hidden state和Decoder hidden state计算新的时间步的Attention分布，进而得到新的上下文向量context vector，使用softmax层对上下文变量解码得到新时间步的词汇分布。  根据当前解码器的隐藏状态$s_t$和输入不同时间步的隐藏状态$h_i$分别计算得到attention分布$a^t​$  计算attention分布对所有的$h_i$加权和  使用$[s_t,h_t^*]​$计算最终的预测值Pointter-genearator network1.pointer-generator网络的关键之处在于使用一个$p_{gen}$来表征从词汇表中生成当前时间步词汇的概率,$（1-p_{gen})$表示从源文本中拷贝词汇的概率。2.$P_{vocab}(w)$表示使用标准seq2seq网络生成词汇的分布，$\sum_{i:w_i=w}a_i^t $表示上下文中所有当前词汇出现是其atttention的和。  计算$P_{gen}​$  与seq2seq attention model相同，计算$P_{vocab}​$  计算$P_{gen}$和$(1-P_{gen})$加权的$P(w)$注：以上图为例，decoder已经输出了Germany beat两个词汇，这时候希望生成下一个时间步的词汇，如果目标词汇$w$未出现在原文中则$\sum _ {i:w_i=w} a_i^t=0$, 如果目标词汇$w$不在词典中则$P_{vocab}(w)=0​$Coverage mechanism1.重复的问题在多句摘要中经常出现，论文中引入覆盖(coverage)机制来监控摘要中生成的词对源文本的覆盖情况，以减少重复关注一部分源文本进而生成重复内容的情况出现。2.coverage vector $c_t= \sum_{t’=0}^{t-1} a^{t’}$等于历史time step的attention之和来表示decoder生成过的词汇的attention覆盖的情况。$c_t$作为下一个时间步计算attention的一个输入，所以pointer-gen网络计算attention那个步骤的公式变为:3.论文引入coverage损失对重复关注同一个位置进行的惩罚,公式为：4.最终的loss是$P(w)$与covLoss之和:result]]></content>
      <categories>
        
          <category> NLP </category>
        
      </categories>
      <tags>
        
          <tag> summarization </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[《The Evolved Transformer》论文总结]]></title>
      <url>/nlp/2019/03/28/The_Evolved_Transformer_review/</url>
      <content type="text"><![CDATA[Google Brain-The Evolved Transformer论文创新点：​	使用神经架构搜索的方法，为 seq2seq 任务找到了一种比Transformer更好的前馈网络架构。架构搜索是基于Transformer进行演进，最终得到的Evolved Transformer 的新架构在四个成熟的语言任务（WMT 2014 英德、WMT 2014 英法、WMT 2014 英捷及十亿词语言模型基准（LM1B））上的表现均优于原版 Transformer。在用大型模型进行的实验中，Evolved Transformer 的效率（FLOPS）是 Transformer 的两倍，而且质量没有损失。在更适合移动设备的小型模型（参数量为 7M）中，Evolved Transformer 的 BLEU 值高出 Transformer 0.7。搜索空间：​	一个模型包含encoder和decoder，各包含若干个单元，编码器的单元包含6个模块，解码器的单元包含8个模块。每个模块分左右两个分支，各自接受一个隐藏状态作为输入。按照层次从低到高分支搜索项分为：input、normalization、layer、output dimension和activation。左右分支通过combiner function合并为新的隐藏状态作为输出。  Input：分支可以从输入池中选择一个隐藏状态作为当前block的输入。单元中的第i个block可以从[0, i]个隐藏状态中进行选择，其中第j个隐藏状态表示该cell中第j个block的输出，第0个候选项为单元的输入。  Normalization：归一化项提供了两个选项， [LAYER NORMALIZATION (Ba et al., 2016), NONE]  Layer：构造一个神经网络层，提供的选项包括：          标准卷积      深度可分离卷积      LIGHTWEIGHT 卷积      n头注意力层      GATED LINEAR UNIT      ATTEND TO ENCODER（decoder专用）      全等无操作      Dead Branch，切断输出        Relative Output Dimension：决定神经网络层输出的维度。  Activation：搜索中激活函数的选项有[SWISH, RELU, LEAKY RELU,  NON]  Combiner Function：表征的是左枝和右枝的结合方式，包括{ADDITION、CONCATENATION、MULTIPLICATION}。如果左右枝最终输出形状不同，则需要使用padding进行填充。短的向量向长的向量对齐，当使用加法进行结合时使用0填充，当使用乘法进行结合时使用1填充。  Number of cells：纵向叠加的cell的数量，搜索范围是[1,6]演进的过程：      锦标赛选择（Tournament Selection）：          tournament selection算法是一种遗传算法，首先随机生成一批个体, 这些个体是一个个由不同组件组成的完整的模型，我们在目标任务上训练这些个体并在验证集上面计算他们的表现。      首先在初始种群中进行采样产生子种群，从子种群中选出适应性（fitness）最高的个体作为亲本（parent）。被选中的亲本进行突变——也就是将网络模型中的一些组件改变为其他的组件——以产生子模型，然后在对这些子模型分配适应度（fitness），在训练集和测试集上进行训练和验证。      对种群重新进行采样，用通过评估的子模型代替子种群中的fitness的个体以生成新的种群。      重复上面的步骤，直到种群中出现超过给定指标的模型。            渐进式动态障碍（Progressive Dynamic Hurdle）：    ​	实验使用的训练集是WMT14英语到德语的机器翻译数据集，完整的训练和验证过程需要很长的时间，如果在所有的子模型上进行完整的训练和验证过程将会耗费很大的计算资源。因此论文中使用渐进式动态障碍的方法来提前停止一些没有前景的模型的训练，转而将更多的计算资源分配那些当前表现更好的子模型。具体来说就是让当前表现最好的一些模型多训练一些step。    ​	假设当前种群经过一次锦标赛选择，生成了m个子模型并且加入到了种群中，这时候计算整个种群fitness的平均值$h_0$,下一次锦标赛选择将会以$h_0$作为对照，生成的另外m个fitness超过$h_0$的子模型可以继续训练$s_1$个step，接着进行种群中的所有的其他个体会继续训练$s_1$个step，然后在新的种群中生成$h_1$，以此类推知道种群中所有的个体的训练step都达到一个指定值。    ​	如果一个子模型是由第$i$次锦标赛选择之后的亲本生成的，那么验证的过程将会进行$i$次。第一次为该模型分配$s_0$次的训练step并且在验证集上进行验证，若验证的fitness大于$h_0$则再分配$s_1$次训练step，再验证，再与$h_1$比较，只有子样本通过${h_0, h_1, …, h_i}$次比较才能作为新的个体加入到新的种群中。  ]]></content>
      <categories>
        
          <category> NLP </category>
        
      </categories>
      <tags>
        
          <tag> Feature_Extractor </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Few-shot Learning 总结]]></title>
      <url>/fewshotlearning/2019/03/26/few_shot_summery_01/</url>
      <content type="text"><![CDATA[N ways K shot few-shot Learning 问题的描述最终训练模型的效果需要达到，给模型之前完全没见过的  $N$ 个新类，每个新类中只有 $K$ 个样本。该模型需要能够通过利用这仅有的 $N \times K$  个样本，来对接下来给出的新样本进行分类。在 RelationNet work 1 的问题描述中，将这给出的 $N \times K$ 个样本集称为 Support Set ，待分类的图片集称为 Query Set。常用的训练步骤训练集中的类的样本不止 $K$ 个样本若我们使用数据集 $D$ 来训练模型， 而 $D$  中所有的类中 $a$ 个样本，eg. mini-imagenet 中每个类有 600 个样本，则  $a=600$。整体的训练过程可以分为多个 meta-learning 的过程，在每个 meta-learning 开始的时候，从训练集 $D$ 中随机抽取 $N$ 个类，每个类中抽取 $K$ 个样本做成 Support Set，除此之外，还从已经抽取得到每个类中，除已抽取的样本外，再抽取 $T$ 个样本作为 Query Set。之后，模型将会去学习如何根据 Support Set 的样本，来正确分类 Query Set 的样本。注：整个 Meta-Learning 的训练过程，模拟的是当模型真正遇到小样本学习的过程。该种方法的模型有：  Relation Network  Matching Network  Prototypical Network  Siamese Network用生成的方式补充小样本分类的方式这种方式，主要分为两个组件，一方面是传统的 DCNN 分类器，如 ResNet，另一方面则是用于生成新的“假”样本的模型。其训练过程为，首先将 DCNN 在已有的大样本数据集上进行训练，得到一个在大样本数据集上表现良好的模型。之后，使用生成模型结合大样本数据集中类的样本和新类中的小样本，生成“假”的新类的图片，直到小样本的类中的样本数和大样本数据集中的类样本数目相同。最后，再使用之前训练的 DCNN 分类器在这些含有生成器生成的“假”样本的新类上进行训练，以达到小样本学习的目的。该种方法的模型有：  Low-shot Learning via Covariance-Preserving Adversarial Augmentation Networks  Low-Shot Learning from Imaginary Data  Low-shot Visual Recognition by Shrinking and Hallucinating Features训练集中的类的样本只有 $K$ 个样本在这种方式中，在训练的时候模型就只能使用每个类只含有 $K$ 个样本的数据集。该种方法的模型有：  Optimization as a Model for Few-Shot LearningRelation NetworkRelation Network 是 few-shot learning 中比较直观的模型。正规的来讲，他分为两部分，一部分是特征提取部分 encoder，另一部分是计算相似度的relation network。其中 relation network，部分就是通过两层全连接层学到输入的两个拼接后的样本的相似度。其模型图如下图所示：注：源码中，5 ways 5 shot 的训练是取得 $5$ 个 Support 样本和 $10$ 个 Query 样本。Prototypical Network这个模型简单的来说就是将图片 encoder 成向量之后，再将 Support Set 中的所有的样本求和取平均成一个向量后，再和 Query 的向量求欧式距离，以代表图片和类别的相似度。Matching NetworkMatching Network 则是用 Query 的样本和 Support 的样本做 Attention 操作，最终得到该图片和其他图片的相似度。            Learning to Compare：Relation Network for Few-Shot Learning CVPR 2018&nbsp;&#8617;      ]]></content>
      <categories>
        
          <category> FewShotLearning </category>
        
      </categories>
      <tags>
        
          <tag> Few_Shot_Learning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
</search>
