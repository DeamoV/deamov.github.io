<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-03-11T00:32:12+08:00</updated><id>http://localhost:4000/</id><title type="html">Pre-Demo-Field</title><subtitle>Work Hard! Play Hard!</subtitle><author><name>DeamoV</name></author><entry><title type="html">第四课 无模型的预测</title><link href="http://localhost:4000/2019/03/11/%E7%AC%AC%E5%9B%9B%E8%AF%BE-%E6%97%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A2%84%E6%B5%8B/" rel="alternate" type="text/html" title="第四课 无模型的预测" /><published>2019-03-11T00:00:00+08:00</published><updated>2019-03-11T00:00:00+08:00</updated><id>http://localhost:4000/2019/03/11/%E7%AC%AC%E5%9B%9B%E8%AF%BE%20%E6%97%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A2%84%E6%B5%8B</id><content type="html" xml:base="http://localhost:4000/2019/03/11/%E7%AC%AC%E5%9B%9B%E8%AF%BE-%E6%97%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A2%84%E6%B5%8B/">---
layout: post
title: &quot;第四课 无模型的预测&quot;
date: 2019-03-11
categories: ReinforceLearning
tags: [&quot;ReinforceLearning&quot;, &quot;强化学习&quot;]
---&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;css/style.css&quot; /&gt;
		&lt;title&gt;第四课 无模型的预测&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;这一课帅小哥主要讲的内容是预测的部分，在第五课会加入控制的部分。其中预测的部分主要是两个相似的算法，一个为 Monte-Carlo（MC），另一个为 Temporal-Difference（TD）。两者的区别主要在于，&lt;strong&gt;MC 为需要在出现终止状态后，才能得到 Reward，而 TD 则是实时的&lt;/strong&gt;。&lt;/p&gt;

&lt;h2&gt;Monte-Carlo&lt;/h2&gt;

&lt;p&gt;Monte-Carlo强化学习指的是，在不清楚 MDP 状态转移和奖励方案的情况下，直接通过经历完整的 episode 来学习状态的 value。一般而言，一个状态的 value 为，其在多个 episode 下的 value 的平均值。&lt;/p&gt;

&lt;p&gt;注：episode 指的是&lt;strong&gt;不定的起始状态&lt;/strong&gt;开始，直到&lt;strong&gt;某一特定的终止状态&lt;/strong&gt;结束。&lt;/p&gt;

&lt;p&gt;其评价每个状态的 value 的主要算法如下两种：&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;首次访问 Monte-Carlo 策略评估

		&lt;p&gt;首先，固定一个策略 $\pi$ ，之后使用这个策略进行多个完整的 episode。对于每个 episode，当且仅当状态第一次出现时才列入计算：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;code-highlighted code-python&quot;&gt;N(s) &lt;span class=&quot;syntax-all syntax-keyword&quot;&gt;=&lt;/span&gt; N(s) &lt;span class=&quot;syntax-all syntax-keyword&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;syntax-all syntax-constant&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# 状态计数 +1
&lt;/span&gt;S(s) &lt;span class=&quot;syntax-all syntax-keyword&quot;&gt;=&lt;/span&gt; S(s) &lt;span class=&quot;syntax-all syntax-keyword&quot;&gt;+&lt;/span&gt; G_t &lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# 总收获更新
&lt;/span&gt;V(s) &lt;span class=&quot;syntax-all syntax-keyword&quot;&gt;=&lt;/span&gt; V(s) &lt;span class=&quot;syntax-all syntax-keyword&quot;&gt;/&lt;/span&gt; N(s) &lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# 状态的 value 更新
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

		&lt;p&gt;&lt;em&gt;注：当 N 很大时， $V(s)$ 就是我们所求估计&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;每次访问 Monte-Carlo 策略评估

		&lt;p&gt;同首次访问 MC 算法一致，但是这个算法中，&lt;strong&gt;每次出现在状态转移链中的状态&lt;/strong&gt;都会更新。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Temporal-Difference&lt;/h2&gt;

&lt;p&gt;首先，在开始 TD 算法前，小哥补充了一个 baby math，即一个求平均值的操作其实是可以写成一种迭代的样式如下：&lt;/p&gt;

$$
\begin{split}
\mu_k &amp;= \frac{1}{k} \sum_{j=1}^k x_j  \\
&amp;= \mu_{k-1} + \frac{1}{k}(x_k-\mu_{k-1})
\end{split}
$$
&lt;p&gt;再抽象点就得到了以下公式：&lt;/p&gt;

$$
\begin{split}
V(S_t) &amp;= V(S_t) + \frac{1}{N(S_t)}(G_t - V(S_t)) \\
&amp; = V(S_t) + \alpha(G_t - V(S_t))
\end{split}  
$$
&lt;p&gt;而 TD 算法就是从这里开始的。TD 算法和 MC 算法不同的地方在于，其不用完成整个 episode 才得到状态的 value，即它可以学到一个不完整的 episode，通过自身的引导（bootstrapping）来猜测结果。其公式如下：&lt;/p&gt;

$$
V(S_T) = V(S_t) + \alpha(R_{t+1} + \gamma V(S_{t+1}) - V(S_t))
$$
&lt;p&gt;&lt;em&gt;注：其中 $R_{t+1}$ 为离开该状态的时候的即刻奖励， $S_{t+1}$ 为下一状态的预估状态价值。&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;TD 与 MC 的对比&lt;/h2&gt;

&lt;ol&gt;
	&lt;li&gt;TD 可以在知道最终结果前就可以学习，MC 必须在 episode 结束后才知道。

		&lt;p&gt;&lt;em&gt;注：小哥举了个例子，说你不能在被车撞死后再重来。&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;MC 是基于某一个策略的无偏估计，而 TD 则是有偏估计。（毕竟 TD 瞎猜了）&lt;/li&gt;
	&lt;li&gt;MC 没有 bias，但是有较高的变异性（Variance），对初值不敏感，而 TD 有 bias，低变异性，但效率高。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;em&gt;注：MDP、TD 和 MC 都是计算状态 value 的方案&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;参考资料&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/dukuku5038/article/details/84557798&quot;&gt;Joey 老师的教程 04&lt;/a&gt; &lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://space.bilibili.com/74997410/video&quot;&gt;David Silver 的强化学习课系列&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;MathJax.Hub.Config({tex2jax: {inlineMath:[['$','$']]}});&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><summary type="html">--- layout: post title: &quot;第四课 无模型的预测&quot; date: 2019-03-11 categories: ReinforceLearning tags: [&quot;ReinforceLearning&quot;, &quot;强化学习&quot;] --- 第四课 无模型的预测 这一课帅小哥主要讲的内容是预测的部分，在第五课会加入控制的部分。其中预测的部分主要是两个相似的算法，一个为 Monte-Carlo（MC），另一个为 Temporal-Difference（TD）。两者的区别主要在于，MC 为需要在出现终止状态后，才能得到 Reward，而 TD 则是实时的。</summary></entry><entry><title type="html">第二课 马尔可夫决策过程 MDP</title><link href="http://localhost:4000/reinforcelearning/2019/03/11/%E7%AC%AC%E4%BA%8C%E8%AF%BE-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-MDP/" rel="alternate" type="text/html" title="第二课 马尔可夫决策过程 MDP" /><published>2019-03-11T00:00:00+08:00</published><updated>2019-03-11T00:00:00+08:00</updated><id>http://localhost:4000/reinforcelearning/2019/03/11/%E7%AC%AC%E4%BA%8C%E8%AF%BE%20%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B%20MDP</id><content type="html" xml:base="http://localhost:4000/reinforcelearning/2019/03/11/%E7%AC%AC%E4%BA%8C%E8%AF%BE-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-MDP/">&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;css/style.css&quot; /&gt;
		&lt;title&gt;第二课 马尔可夫决策过程 MDP&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;Markov Decision Process 是强化学习的核心，帅气的 David 说所有的强化学习问题都可以转化为 MDP，即就像 RBM 是深度学习的发源地一样，MDP 是整个强化学习的基础。而和名字一样，我们需要首先理解 Markov 和 Decision（Reward），接下来会从 Markov 过程到 Markov 过程加上 Reward 之后的马尔可夫奖励过程，最后引入 Bellman 方程，通过解 Bellman 方程的方式深入了解到底何为决策。&lt;/p&gt;

&lt;h2&gt;马尔可夫过程 Markov Process&lt;/h2&gt;

&lt;p&gt;谈到 Markov 过程，就需要提到 Markov 的一个前提条件，即 &lt;strong&gt;Markov Process 认为下一个 t+1 时刻的状态，仅同当前 t 时刻的状态有关&lt;/strong&gt;。David 帅大大，对此的解释是认为其当前的状态其实已经包含了之前的状态的信息了。所以就可以用下面的公式表达状态转移概率了：&lt;/p&gt;

$$
P_{ss'} = P[S_{t+1} = s' | S_t = s]
$$
&lt;p&gt;接下来我们联想当年求最短路径的算法 Floyd 的那个矩阵，我们只需要用矩阵 $S_t$ 表示当前的状态，再使用矩阵 $P$ 作为代表不同状态之间的转移概率，两者相乘就能得到下一时刻的状态矩阵 $S_{t+1}$ 。而 Markov Process 就是这个当前状态 $S$ 和概率转移矩阵 $P$ 不停相乘的过程，简单的计为 $&lt;S, P&gt;$ 。&lt;/p&gt;

$$
P = \left[ \begin{array}{cc}
        P_{11} &amp; P_{12} &amp; P_{13} &amp; ... &amp; P_{1n} \\ 
        P_{21} &amp; P_{22} &amp; P_{23} &amp; ... &amp; P_{2n} \\
		... &amp; ... &amp; ... &amp; ... &amp; ... \\
		P_{n1} &amp; P_{n2} &amp; P_{n3} &amp; ... &amp; P_{nn} 
        \end{array} 
\right]
$$
&lt;p&gt;&lt;em&gt;注：其中由于 $P$ 中每一行代表着行号表示的状态转移到另一个状态的所有情况，所以每一行的概率和一定等于 1&lt;/em&gt; &lt;/p&gt;

&lt;h2&gt;马尔可夫奖励过程 Markov Reward Process&lt;/h2&gt;

&lt;p&gt;上一部分我们讲的 Markov Process 它还是没有奖励的，也就是说没有一个评判的依据，当我们把奖励引入的话就成了 MRP 了。在引入的过程中，我们用 $\gamma$ 作为衰减系数，表达对未来的收益的看重程度。这样我们对 MRP 就记为 $&lt; S,P,R, \gamma &gt;$ 。&lt;/p&gt;

&lt;p&gt;接下来，我们进入细节的部分。为了更方便说明价值函数 $v(s)$，我们引入一个叫做收益 Return 的符号，其代表了当前状态，结合一定的未来情况能拿到的奖励，记做 $G_t$。&lt;/p&gt;

$$
G_t = R_{t+1} + \gamma R_{t+2} + ... = \sum_{k=0}^{\inf}\gamma^k R_{t+k+1}
$$
&lt;p&gt;现在就可以讲述价值函数是什么了，其衡量了当前的状态的长期价值，即马尔科夫奖励过程中，从该状态开始的马尔科夫的收益的期望：&lt;/p&gt;

$$
v(s) = E[G_t|S_t = s]
$$
&lt;p&gt;&lt;em&gt;注：聪明的朋友已经发现了，这里的 $v(s)$ 的值和 $G_t$ 的定义很相似，之后在 Bellman 方程中就会体现。 &lt;/em&gt;&lt;/p&gt;

&lt;h3&gt;Bellman 方程&lt;/h3&gt;

&lt;p&gt;现在们有了上面的价值函数的表达式了，但是似乎还是看不出什么好玩的地方，接下来我们把它展开，进行推导，会得到很有趣的结果：&lt;/p&gt;

\begin{split}
v(s) &amp;= E[G_t|S_t = s] \\
&amp;= E[R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + ... | S_t = s] \\
&amp;= E[R_{t+1} + \gamma (R_{t+2} + \gamma R_{t+3} + ...) | S_t =s] \\
&amp;= E[R_{t+1} + \gamma G_{t+1} | S_t = s] \\
&amp;= E[R_{t+1} + \gamma v(S_{t+1}) | S_t = s] \\
&amp;= R_s + \gamma \sum_{s' \in \mathcal{S}} \mathcal{p}_{ss'} v(s') 
\end{split}
&lt;p&gt;接下来换成矩阵的形式为：&lt;/p&gt;

$$
v = \mathcal{R} + \gamma \mathcal{P}v  
$$
&lt;p&gt;把矩阵写开为：&lt;/p&gt;

$$
\left[ \begin{array}{cc}
        v(1) \\ 
        ... \\
		v(n)
        \end{array} 
\right] =

\left[ \begin{array}{cc}
        R_1 \\ 
        ... \\
		R_n
        \end{array} 
\right] +

\gamma

\left[ \begin{array}{cc}
        P_{11}&amp; ... &amp; P_{1n} \\ 
		... &amp; ... &amp; ... \\
		P_{n1} &amp; ... &amp; P_{nn} 
        \end{array} 
\right]
\left[ \begin{array}{cc}
        v(1) \\ 
        ... \\
		v(n)
        \end{array} 
\right]
$$
&lt;p&gt;这样我们就可以直接求解：&lt;/p&gt;

$$
v = (1 - \gamma \mathcal{P})^{-1} \mathcal{R}  
$$
&lt;p&gt;&lt;strong&gt;但是遗憾的是，计算复杂度为 $O(n^3)$ ，该算法的时间复杂度很高&lt;/strong&gt;。对此，大规模MRP的求解通常使用迭代法。常用的迭代方法有：&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;动态规划 Dynamic Programming&lt;/li&gt;
	&lt;li&gt;蒙特卡洛评估 Monte-Carlo evaluation&lt;/li&gt;
	&lt;li&gt;时序差分学习 Temporal-Difference&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;马尔可夫决策过程 Markov Decision Process&lt;/h2&gt;

&lt;p&gt;在 MRP 中我们还没有引入 Action，而我们 MDP 的目的则是找出最佳的 Action，于是 MDP 便引入了&lt;strong&gt;有限行为集合&lt;/strong&gt; $A$ ，记做 $&lt; S,A,P,R,\gamma &gt;$ 。接下来，我们就引入了第一课中提到的策略 $\pi$ , 策略是概率的集合或分布，代表着当前状态 $s$ 采取行为 $s$ 的概率，用 $\pi(a|s)$ 表示。&lt;/p&gt;

&lt;p&gt;这样从状态 $s$ 到下一个状态 $s'$ 就需要考虑到动作的因素，于是在策略 $\pi$ 下，又 $s$ 转移到 $s'$ 的转移概率为：&lt;/p&gt;

$$
\mathcal{P}_{s,s'}^{\pi} = \sum_{a\in\mathcal{A}} \pi(a|s)\mathcal{R}_{ss'}^a  
$$
&lt;p&gt;同时奖励函数变为：&lt;/p&gt;

$$
\mathcal{R}_s^{\pi} = \sum_{a\in A} \pi(a|s)\mathcal{R}_s^a  
$$
&lt;p&gt;这样基于策略 $\pi$ 的价值函数为：&lt;/p&gt;

$$
\begin{split}
v_{\pi}(s) &amp;= E_{\pi}[G_t | S_t = s] \\ 
&amp;= E_{\pi}[R_{t+1} + \gamma v_{\pi}(S_{t+1}) | S_t = s]
\end{split}
$$
&lt;p&gt;行为价值函数 $q_{\pi}(s, a)$ 则为：&lt;/p&gt;

$$
\begin{split}
q_{\pi}(s, a)&amp;=E_{\pi}[G_t | S_t = s， A_t = a] \\
&amp;=E_{\pi}[R_{t+1} + \gamma q_{\pi}(S_{t+1}, A_{t+1}) | S_t = s, A_t = a]
\end{split}
$$
&lt;p&gt;接下来我们在看 Bellman 方程，接下来我们做的是看如何把两个价值函数连在一起，他们之前的关系如下：&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot; https://ws4.sinaimg.cn/large/006tKfTcly1g0y5t543inj31g20u0759.jpg &quot;/&gt;&lt;/figure&gt;

&lt;figure&gt;&lt;img src=&quot;https://ws4.sinaimg.cn/large/006tKfTcly1g0y5t0ezftj31f00u03zp.jpg&quot;/&gt;&lt;/figure&gt;

&lt;p&gt;接下来把他们合起来，如下图所示，则公式为：&lt;/p&gt;

$$
v_{\pi}(s) = \sum_{a \in A} \pi(a|s) (\mathcal{R}_s^a + \gamma \sum_{s' \in \mathcal{S}} v_{\pi}(s'))  
$$
$$
q_{\pi}(s,a)=\mathcal{R}_s^{a} + \gamma \sum_{s' \in \mathcal{S}} \mathcal{P}_{ss'}^a (\sum_{a' \in \mathcal{A}} \pi(a'|s')q_{\pi}(s',a'))
$$
&lt;h3&gt;决策&lt;/h3&gt;

&lt;p&gt;公式写完了，我们接下来就是要进入决策过程，分为两个一个是价值函数最优。简单的来说，就是选一个策略让 $v(s)$ 和 $q(s,a)$ 最大，公式如下：&lt;/p&gt;

$$
v_* = max_{\pi} v_{\pi}(s)
$$
$$
q_* = max_{\pi} q_{\pi}(s,a)
$$
&lt;p&gt;这个解是否存在呢，David 帅哥说存在的，对于任何MDP，下面几点成立：&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;存在一个最优策略，比任何其他策略更好或至少相等&lt;/li&gt;
	&lt;li&gt;所有的最优策略有相同的最优价值函数&lt;/li&gt;
	&lt;li&gt;所有的最优策略具有相同的行为价值函数&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上定理奠定了我们理论上能找到最优策略。那么既然存在我们应该怎么找呢，当然是用 Bellman 最优方程了，遗憾的是，这个同深度学习一样，函数是非线性的所以不能直接求解，需要通过迭代的方式。Bellman 最优方程如下：&lt;/p&gt;

$$
v_*(s) = max_a \mathcal{R}_s^a + \gamma \sum_{s' \in \mathcal{S}} \mathcal{P}_{ss'}^a v_*(s')  
$$
$$
q_*(s,a) = \mathcal{R}_s^a + \gamma \sum_{s' \in \mathcal{S}} \mathcal{P}_{ss'}^a max_{a'}q_*(s', a') 
$$
&lt;p&gt;&lt;em&gt;注：解的迭代方法有价值迭代、策略迭代、Q学习、Sarsa等&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;参考链接&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/dukuku5038/article/details/84361371&quot;&gt;Joey 老师的教程 02&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://space.bilibili.com/74997410/video&quot;&gt;David Silver 的强化学习课系列&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><category term="ReinforceLearning" /><category term="强化学习" /><summary type="html">第二课 马尔可夫决策过程 MDP Markov Decision Process 是强化学习的核心，帅气的 David 说所有的强化学习问题都可以转化为 MDP，即就像 RBM 是深度学习的发源地一样，MDP 是整个强化学习的基础。而和名字一样，我们需要首先理解 Markov 和 Decision（Reward），接下来会从 Markov 过程到 Markov 过程加上 Reward 之后的马尔可夫奖励过程，最后引入 Bellman 方程，通过解 Bellman 方程的方式深入了解到底何为决策。</summary></entry><entry><title type="html">第三课 动态规划寻找最优策略</title><link href="http://localhost:4000/2019/03/11/%E7%AC%AC%E4%B8%89%E8%AF%BE-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%AF%BB%E6%89%BE%E6%9C%80%E4%BC%98%E7%AD%96%E7%95%A5/" rel="alternate" type="text/html" title="第三课 动态规划寻找最优策略" /><published>2019-03-11T00:00:00+08:00</published><updated>2019-03-11T00:00:00+08:00</updated><id>http://localhost:4000/2019/03/11/%E7%AC%AC%E4%B8%89%E8%AF%BE%20%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%AF%BB%E6%89%BE%E6%9C%80%E4%BC%98%E7%AD%96%E7%95%A5</id><content type="html" xml:base="http://localhost:4000/2019/03/11/%E7%AC%AC%E4%B8%89%E8%AF%BE-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%AF%BB%E6%89%BE%E6%9C%80%E4%BC%98%E7%AD%96%E7%95%A5/">---
layout: post
title: &quot;第三课 动态规划寻找最优策略P&quot;
date: 2019-03-11
categories: ReinforceLearning
tags: [&quot;ReinforceLearning&quot;, &quot;强化学习&quot;]
---&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;css/style.css&quot; /&gt;
		&lt;title&gt;第三课 动态规划寻找最优策略&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;这节课是接着第二节课的，个人对这节课的总结只有一句话&lt;strong&gt;对 Bellman 方程多次迭代能得到最优策略和最大价值&lt;/strong&gt;。课程开始的时候，David 大佬答大体讲了下什么是动态规划，这个想必大家都很熟悉了，就不赘述了。我们仔细想 Bellman 方程其实是完美的复合了动态规划的要求的条件的。所以我们就有了以下的内容。&lt;/p&gt;

&lt;h2&gt;Iterative Policy Evaluation&lt;/h2&gt;

&lt;figure&gt;&lt;img src=&quot; https://ws3.sinaimg.cn/large/006tKfTcly1g0y5xaqtc1j31dk0u0q3x.jpg &quot;/&gt;&lt;/figure&gt;

&lt;p&gt;简单的来说就是重复迭代上述的过程，最终 $v(s)$ 会收敛到最大值，这样子我们就能评估当前选择的 Policy $\pi$ 好不好了。下图为算法收敛的过程。&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;https://ws3.sinaimg.cn/large/006tKfTcly1g0y5x7q25wj316w0u0q45.jpg&quot;/&gt;&lt;/figure&gt;

&lt;h2&gt;How to Improve a Policy&lt;/h2&gt;

&lt;p&gt;有了 Policy 的评估之后，直觉上我们就有了下面的算法，就是每个步骤都看看当前策略候选集中的最优策略是什么，并选择最优的策略。&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;https://ws3.sinaimg.cn/large/006tKfTcly1g0y5x57arsj319b0u0myw.jp&quot;/&gt;&lt;/figure&gt;

&lt;p&gt;由于整个算法最终会收敛到唯一的最优策略和最大 value，所以我们就不停的迭代上述步骤就好啦。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;注：收敛是因为每次贪婪的选择最优策略一定会导致下一步的结果更好，同时 MDP 保证了其最优策略等价于最优 value。&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;总结&lt;/h2&gt;

&lt;figure&gt;&lt;img src=&quot;https://ws4.sinaimg.cn/large/006tKfTcly1g0y5x1sg24j318p0u0q5i.jpg&quot;/&gt;&lt;/figure&gt;

&lt;p&gt;可以这么理解，Value Iteration 是为了评估目前可选的 Policy，Policy Iteration 就是根据评估找出当前最好的 Policy。之后重复上述两个步骤就能得到最优 Policy。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;注：之后其实还讲了异步动态规划、 采样更新、近似动态规划，但是我们实际很少使用这些，所以就不在这里提了。&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;参考文献&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/dukuku5038/article/details/84516559&quot;&gt;Joey 老师的教程 03&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://space.bilibili.com/74997410/video&quot;&gt;David Silver 的强化学习课系列&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><summary type="html">--- layout: post title: &quot;第三课 动态规划寻找最优策略P&quot; date: 2019-03-11 categories: ReinforceLearning tags: [&quot;ReinforceLearning&quot;, &quot;强化学习&quot;] --- 第三课 动态规划寻找最优策略 这节课是接着第二节课的，个人对这节课的总结只有一句话对 Bellman 方程多次迭代能得到最优策略和最大价值。课程开始的时候，David 大佬答大体讲了下什么是动态规划，这个想必大家都很熟悉了，就不赘述了。我们仔细想 Bellman 方程其实是完美的复合了动态规划的要求的条件的。所以我们就有了以下的内容。</summary></entry><entry><title type="html">第一课 强化学习简介</title><link href="http://localhost:4000/reinforcelearning/2019/03/11/%E7%AC%AC%E4%B8%80%E8%AF%BE_%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80/" rel="alternate" type="text/html" title="第一课 强化学习简介" /><published>2019-03-11T00:00:00+08:00</published><updated>2019-03-11T00:00:00+08:00</updated><id>http://localhost:4000/reinforcelearning/2019/03/11/%E7%AC%AC%E4%B8%80%E8%AF%BE_%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80</id><content type="html" xml:base="http://localhost:4000/reinforcelearning/2019/03/11/%E7%AC%AC%E4%B8%80%E8%AF%BE_%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80/">&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;css/style.css&quot; /&gt;
		&lt;title&gt;第一课 强化学习简介&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;h2&gt;强化学习是什么&lt;/h2&gt;
&lt;p&gt;强化学习在不同领域有不同的表现形式：神经科学、心理学、计算机科学、工程领域、数学、经济学等有不同的称呼。&lt;/p&gt;
&lt;figure&gt;&lt;img src=&quot;https://ws4.sinaimg.cn/large/006tKfTcly1g0y5qpobzkj319n0u0tes.jpg&quot;/&gt;&lt;/figure&gt;

&lt;p&gt;而强化学习是单独的一个机器学习的分支，他不属于监督学习，也不属于无监督学习。他的特点如下：&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;没有监督数据、只有奖励信号&lt;/li&gt;
	&lt;li&gt;奖励信号不一定是实时的，很可能会延后很多&lt;/li&gt;
	&lt;li&gt;时间（序列）是一个关键因素&lt;/li&gt;
	&lt;li&gt;当前的行为会影响后续的数据&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;注：之前的深度学习，机器学习这些是基于数据的，而强化学习则是&lt;strong&gt;基于模拟实验的&lt;/strong&gt;。&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;强化学习问题的组成&lt;/h2&gt;

&lt;figure&gt;&lt;img src=&quot;https://ws4.sinaimg.cn/large/006tKfTcly1g0y5qmcke3j30v50u0n1y.jpg&quot;/&gt;&lt;/figure&gt;

&lt;h3&gt;奖励 Reward&lt;/h3&gt;

&lt;p&gt; $R_t$ 是一个信号的反馈，是一个标量，而个体的工作就是最大化奖励总和（长期收益最大）。小哥说这个奖励用标量就已经足够了。 &lt;/p&gt;

&lt;h3&gt;Agent &amp;amp; Environment&lt;/h3&gt;

&lt;p&gt;首先要注意的是&lt;strong&gt;智能体是不能直接得到环境的信息的&lt;/strong&gt;。只能通过&lt;strong&gt;观察&lt;/strong&gt;得到 $t$ 时间的观察评估 $O_t$ ，之后根据观察的结果选择行为 $A_t$，最终环境给智能体一个奖励信号 $R_{t+1}$。&lt;/p&gt;

&lt;p&gt;而环境则可以接受智能体的动作，并以此更新环境。同时也能反馈个诶智能体奖励信号 $R_t$ &lt;/p&gt;

&lt;h2&gt;状态和历史&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;历史是一个观测、行为、奖励的序列&lt;/strong&gt;，这个序列如果全部记录下来的话太耗资源了。所以希望使用状态来表示已有的信息。这个是通过 Markov 的性质实现的。&lt;/p&gt;

&lt;h3&gt;环境状态&lt;/h3&gt;

&lt;p&gt;是环境的私有呈现，包括环境用来决定下一个观测/奖励的所有数据，通常对个体并不完全可见，也就是个体有时候并不知道环境状态的所有细节。即使有时候环境状态对个体可以是完全可见的，这些信息也可能包含着一些无关信息。&lt;/p&gt;

&lt;p&gt;而环境是否可观测，则是区分强化学习算法的一种分类方式：&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;完全可观测环境

		&lt;p&gt;这种问题可以看做一个 Markov Decision Process。&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;部分可观测环境

		&lt;ul&gt;
			&lt;li&gt;用个体已知的概率分布来预测&lt;/li&gt;
			&lt;li&gt;使用 RNN&lt;/li&gt;
		&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;智能体状态&lt;/h3&gt;

&lt;p&gt;包含智能体可以使用的、决定策略使用的所有信息。一般是一个历史的函数 $S_t^a = f(H_t)$ &lt;/p&gt;

&lt;h3&gt;信息状态&lt;/h3&gt;

&lt;p&gt;包括历史上所有的有用的信息，个人直观的感觉为是用在在智能体状态的一部分。&lt;/p&gt;

&lt;h2&gt;强化学习智能体&lt;/h2&gt;

&lt;h3&gt;主要成分&lt;/h3&gt;

&lt;ul&gt;
	&lt;li&gt;策略 Policy

		&lt;p&gt;通过当前状态决定选择哪个动作，即输入是状态，输出是动作。&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;价值函数 Value Function

		&lt;p&gt;对未来的奖励的预期，用于评价当前状态的好坏程度。&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;模型 Model

		&lt;p&gt;用于对环境的建模&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;强化学习智能体的分类&lt;/h3&gt;

&lt;ol&gt;
	&lt;li&gt;仅基于价值函数的 Value Based：在这样的个体中，有对状态的价值估计函数，但是没有直接的策略函数，策略函数由价值函数间接得到。&lt;/li&gt;
	&lt;li&gt;仅直接基于策略的 Policy Based：这样的个体中行为直接由策略函数产生，个体并不维护一个对各状态价值的估计函数。&lt;/li&gt;
	&lt;li&gt;演员-评判家形式 Actor-Critic：个体既有价值函数、也有策略函数。两者相互结合解决问题。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;此外，根据个体在解决强化学习问题时是否建立一个对环境动力学的模型，将其分为两大类：&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;不基于模型的个体: 这类个体并不视图了解环境如何工作，而仅聚焦于价值和/或策略函数。&lt;/li&gt;
	&lt;li&gt;基于模型的个体：个体尝试建立一个描述环境运作过程的模型，以此来指导价值或策略函数的更新。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;强化学习的矛盾&lt;/h2&gt;

&lt;p&gt;探索 Exploration 和利用 Explotiation，简单的来说就是我们已有一个最优策略，如果不改变的话收益是已知的，而探索的结果是不确定的收益可能增加也可能减少。就和我们人类做决策一样，如何平衡这种矛盾也是强化学习中的一个很有趣的问题。&lt;/p&gt;

&lt;h2&gt;参考&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;http://101.96.10.63/www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/intro_RL.pdf&quot;&gt;官方课件&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/28084904&quot;&gt;大佬的详细笔记&lt;/a&gt; （个人的笔记大多是选择里面个人认为重要的部分）&lt;/li&gt;
&lt;/ul&gt;

&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><category term="ReinforceLearning" /><category term="强化学习" /><summary type="html">第一课 强化学习简介 强化学习是什么 强化学习在不同领域有不同的表现形式：神经科学、心理学、计算机科学、工程领域、数学、经济学等有不同的称呼。</summary></entry><entry><title type="html">深度学习自动调参之NNI样例分析</title><link href="http://localhost:4000/nni/2018/12/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%8A%A8%E8%B0%83%E5%8F%82%E4%B9%8BNNI%E6%A0%B7%E4%BE%8B%E5%88%86%E6%9E%90/" rel="alternate" type="text/html" title="深度学习自动调参之NNI样例分析" /><published>2018-12-16T00:00:00+08:00</published><updated>2018-12-16T00:00:00+08:00</updated><id>http://localhost:4000/nni/2018/12/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%8A%A8%E8%B0%83%E5%8F%82%E4%B9%8BNNI%E6%A0%B7%E4%BE%8B%E5%88%86%E6%9E%90</id><content type="html" xml:base="http://localhost:4000/nni/2018/12/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%8A%A8%E8%B0%83%E5%8F%82%E4%B9%8BNNI%E6%A0%B7%E4%BE%8B%E5%88%86%E6%9E%90/">&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;css/style.css&quot; /&gt;
		&lt;title&gt;深度学习自动调参之NNI样例分析&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-7c9ad7544cf87c62.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot;/&gt;&lt;/figure&gt;
&lt;p&gt;在之前的博文中介绍了 NNI 与其他自动机器学习工具的比较，NNI 的安装和使用等内容，这篇文章你将看到：&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;如何修改 NNI 官方的 mnist-annotation 例子的配置文件；&lt;/li&gt;
	&lt;li&gt;官方例子支持的 Tuner 介绍；&lt;/li&gt;
	&lt;li&gt;各个 Tuner 的训练结果以及结果分析。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;一、配置文件&lt;/h2&gt;

&lt;p&gt;将 NNI 项目 clone 到本地，进入到目录 &lt;code&gt;~/nni/examples/trials/mnist-annotation&lt;/code&gt; ，NNI 有两种配置方式，分别为 Annotation 和 Assessor，nni 官方给的例子是用 Annotation 的配置方式（Assessor 可参见&lt;a href=&quot;https://github.com/Microsoft/nni/blob/master/zh_CN/docs/ExperimentConfig.md&quot;&gt;官方 experiment 配置参考文档&lt;/a&gt;），配置文件 &lt;code&gt;config.yml&lt;/code&gt; 默认参数配置如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;code-highlighted code-python&quot;&gt;authorName: default
&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# authorName 是创建 Experiment 的作者。（你自己的名字 o(*￣▽￣*) ブ）
&lt;/span&gt;
experimentName: example_mnist
&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# experimentName 是 Experiment 的名称。
&lt;/span&gt;trialConcurrency: &lt;span class=&quot;syntax-all syntax-constant&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;#    **trialConcurrency** 定义了并行运行的 trails 的数量。
&lt;/span&gt;&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;#    注意：如果 trialGpuNum 大于空闲的 GPU 数量，Trial 任务会被放入队列，等待分配 GPU 资源。
&lt;/span&gt;
maxExecDuration: &lt;span class=&quot;syntax-all syntax-constant&quot;&gt;1&lt;/span&gt;h
&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# maxExecDuration 定义 Experiment 执行的最长时间。时间单位：{**s**, **m**, **h**, **d**}，分别代表：{*seconds*, *minutes*, *hours*, *days*}。
&lt;/span&gt;&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;#    注意：maxExecDuration 设置的是 Experiment 执行的时间，不是 Trial 的。 如果 Experiment 达到了设置的最大时间，Experiment 不会停止，但不会再启动新的 Trial 作业。
&lt;/span&gt;
maxTrialNum: &lt;span class=&quot;syntax-all syntax-constant&quot;&gt;10&lt;/span&gt;
&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# maxTrialNum 定义了你此次 Experiment 总共想要 NNI 跑多少 Trial。
&lt;/span&gt;trainingServicePlatform: local
&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;#choice: local, remote, pai
&lt;/span&gt;&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# trainingServicePlatform 定义运行 Experiment 的平台
&lt;/span&gt;&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# local：在本机的 ubuntu 上运行 Experiment。
&lt;/span&gt;&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# remote：将任务提交到远程的 Ubuntu 上，必须用 **machineList** 来指定远程的 SSH 连接信息。
&lt;/span&gt;&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# pai：提交任务到微软开源的 OpenPAI 上。
&lt;/span&gt;&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# kubeflow 提交任务至 Kubeflow NNI 支持基于 Kubeflow 的 Kubenetes，以及 Azure Kubernetes
&lt;/span&gt;
useAnnotation: true
&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;#choice: true, false
&lt;/span&gt;&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;#定义使用标记来分析代码并生成搜索空间。（官方例子使用的是 Annotation，所以 useAnnotation = true）
&lt;/span&gt;
tuner:
  builtinTunerName: &lt;span class=&quot;syntax-all syntax-constant&quot;&gt;TPE&lt;/span&gt;
  &lt;span class=&quot;syntax-all syntax-comment&quot;&gt;#builtinTunerName 指定了系统 Tuner 的名字，NNI SDK 提供了多种 Tuner，如：{TPE, Random, Anneal, Evolution, BatchTuner, GridSearch}。
&lt;/span&gt;  &lt;span class=&quot;syntax-all syntax-comment&quot;&gt;#choice: TPE, Random, Anneal, Evolution, BatchTuner
&lt;/span&gt;  &lt;span class=&quot;syntax-all syntax-comment&quot;&gt;#SMAC (SMAC should be installed through nnictl)
&lt;/span&gt;  classArgs:
   &lt;span class=&quot;syntax-all syntax-comment&quot;&gt;#classArgs** 指定了 Tuner 算法的参数。 如果 builtinTunerName 是{TPE, Random, Anneal, Evolution}，用户需要设置 optimize_mode。
&lt;/span&gt;    &lt;span class=&quot;syntax-all syntax-comment&quot;&gt;#choice: maximize, minimize
&lt;/span&gt;    optimize_mode: maximize

trial:
  command: python3 mnist.py
  codeDir: .
  gpuNum: &lt;span class=&quot;syntax-all syntax-constant&quot;&gt;0&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;二、tuner 对比实验&lt;/h2&gt;

&lt;h3&gt;2.1、Random&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;建议场景&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在每个 Trial 运行时间不长（例如，能够非常快的完成，或者很快的被 Assessor 终止），并有充足计算资源的情况下。 或者需要均匀的探索搜索空间。 随机搜索可作为搜索算法的基准线。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参数&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;strong&gt;optimize_mode&lt;/strong&gt; (&lt;em&gt;maximize 或 minimize，可选，默认值为 maximize&lt;/em&gt;) - 如果为 &amp;#39;maximize&amp;#39;，Tuner 会给出有可能产生较大值的参数组合。 如果为 &amp;#39;minimize&amp;#39;，Tuner 会给出有可能产生较小值的参数组合。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;使用样例：&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;code-highlighted code-python&quot;&gt;&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# config.yml
&lt;/span&gt;tuner:
  builtinTunerName: Random
  classArgs:
    optimize_mode: maximize&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;训练结果：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;以下为 Tuner 为 Random，TrialNum 为 30 时的训练结果，从下图右下角可以直观的得出，最大正确率为 98.28%，展开后可看到对应的超参值，在 Trails Detail 能够看到所有 Trails 在不同超参选择上的分布，便于分析。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;卷积核大小：7×7

隐藏层：512

学习率：0.0018762964666695628

激活函数：ReLU

池化层：最大池化

batch size：32

dropout rate：0.5&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-75e7b204750c6914.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;Random.png&quot;/&gt;&lt;figcaption&gt;Random.png&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-6d611848bccf5b8b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;Random2.png&quot;/&gt;&lt;figcaption&gt;Random2.png&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;结果分析：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;正确率低于 30% 的 trails 隐藏层多数为 1024，学习率绝大多数低于 0.001，激活函数多数为 sigmoid。于此同时，正确率高于 90% 的 trails 卷积核大小大部分为 7×7，学习率主要分布在 0.001 以下。&lt;/p&gt;

&lt;p&gt;根据以上对结果的分析，可以合理猜测，此模型下设置卷积核大小为 7×7，学习率低于 0.001，激活函数选用 relu 或 tanh，就能获得比较理想的正确率。&lt;/p&gt;

&lt;h3&gt;2.2、TPE&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;建议场景&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;TPE 是一种黑盒优化方法，可以使用在各种场景中，通常情况下都能得到较好的结果。 特别是在计算资源有限，只能运行少量 Trial 的情况。 大量的实验表明，TPE 的性能远远优于随机搜索。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参数&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;strong&gt;optimize_mode&lt;/strong&gt; (&lt;em&gt;maximize 或 minimize，可选，默认值为 maximize&lt;/em&gt;) - 如果为 &amp;#39;maximize&amp;#39;，Tuner 会给出有可能产生较大值的参数组合。 如果为 &amp;#39;minimize&amp;#39;，Tuner 会给出有可能产生较小值的参数组合。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;使用样例：&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;code-highlighted code-python&quot;&gt;&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# config.yml
&lt;/span&gt;tuner:
  builtinTunerName: &lt;span class=&quot;syntax-all syntax-constant&quot;&gt;TPE&lt;/span&gt;
  classArgs:
    optimize_mode: maximize&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;训练结果：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;以下为 tuner 为 TPE，TrialNum 为 30 时的训练结果，从下图右下角可以直观的得出，最大正确率为 98.13%，展开后可看到对应的超参值：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;卷积核大小：7×7

隐藏层：1024

学习率：0.0005779853380708741

激活函数：ReLU

池化层：最大池化

batch size：16

dropout rate：0.5&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-cd8b11dc08e0ee6d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;TPE.png&quot;/&gt;&lt;figcaption&gt;TPE.png&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-8a44d8f36a54631e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;TPE2.png&quot;/&gt;&lt;figcaption&gt;TPE2.png&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;结果分析：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;正确率前 50% 的 trails 隐藏层多数为 1024，学习率全部低于 0.001，激活函数多数为 relu 和 tanh，卷积核大小大部分为 7×7 和 5×5。&lt;/p&gt;

&lt;p&gt;根据以上对结果的分析，可以合理猜测，此模型下设置卷积核大小为 7×7 或 5×5，学习率低于 0.001，激活函数选用 relu 或 tanh，就能获得比较理想的正确率。&lt;/p&gt;

&lt;h3&gt;2.3、Anneal&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;建议场景&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当每个 Trial 的时间不长，并且有足够的计算资源时使用（与随机搜索基本相同）。 或者搜索空间的变量能从一些先验分布中采样。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参数&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;strong&gt;optimize_mode&lt;/strong&gt; (&lt;em&gt;maximize 或 minimize，可选，默认值为 maximize&lt;/em&gt;) - 如果为 &amp;#39;maximize&amp;#39;，Tuner 会给出有可能产生较大值的参数组合。 如果为 &amp;#39;minimize&amp;#39;，Tuner 会给出有可能产生较小值的参数组合。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;使用样例：&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;code-highlighted code-python&quot;&gt;&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# config.yml
&lt;/span&gt;tuner:
  builtinTunerName: Anneal
  classArgs:
    optimize_mode: maximize&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;训练结果：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;以下为 tuner 为 Anneal，TrialNum 为 100 时的训练结果，从下图右下角可以直观的得出，最大正确率为 98.89%，展开后可看到对应的超参值：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;code-highlighted code-python&quot;&gt;卷积核大小：&lt;span class=&quot;syntax-all syntax-constant&quot;&gt;7&lt;/span&gt;×&lt;span class=&quot;syntax-all syntax-constant&quot;&gt;7&lt;/span&gt;

隐藏层：&lt;span class=&quot;syntax-all syntax-constant&quot;&gt;512&lt;/span&gt;

学习率：&lt;span class=&quot;syntax-all syntax-constant&quot;&gt;0.0010559236204399935&lt;/span&gt;

激活函数：ReLU

池化层：最大池化

batch size：&lt;span class=&quot;syntax-all syntax-constant&quot;&gt;32&lt;/span&gt;

dropout rate：&lt;span class=&quot;syntax-all syntax-constant&quot;&gt;0.5&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-1b73ccb5bec4e58a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;Anneal.png&quot;/&gt;&lt;figcaption&gt;Anneal.png&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-898cf3360b2df250.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;Anneal2.png&quot;/&gt;&lt;figcaption&gt;Anneal2.png&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;结果分析：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;正确率前 20% 的 trails 隐藏层基本分布于 512 和 1024，学习率分布在 0.001 左右，激活函数为 relu，卷积核大小大部分为 5×5。&lt;/p&gt;

&lt;p&gt;根据以上对结果的分析，可以合理猜测，此模型下设置卷积核大小为 5×5，学习率在 0.001 左右，激活函数选用 relu，隐藏层为 1024 或 512，就能获得比较理想的正确率。&lt;/p&gt;

&lt;h3&gt;2.4、Evolution&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;建议场景&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;此算法对计算资源的需求相对较高。 需要非常大的初始种群，以免落入局部最优中。 如果 Trial 时间很短，或者利用了 Assessor，就非常适合此算法。 如果 Trial 代码支持权重迁移，即每次 Trial 会从上一轮继承已经收敛的权重，建议使用此算法。 这会大大提高训练速度。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参数&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;strong&gt;optimize_mode&lt;/strong&gt; (&lt;em&gt;maximize 或 minimize，可选，默认值为 maximize&lt;/em&gt;) - 如果为 &amp;#39;maximize&amp;#39;，Tuner 会给出有可能产生较大值的参数组合。 如果为 &amp;#39;minimize&amp;#39;，Tuner 会给出有可能产生较小值的参数组合。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;使用样例：&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;code-highlighted code-python&quot;&gt;&lt;span class=&quot;syntax-all syntax-comment&quot;&gt;# config.yml
&lt;/span&gt;tuner:
  builtinTunerName: Evolution
  classArgs:
    optimize_mode: maximize&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;训练结果：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;以下为 Tuner 为 Evolution，TrialNum 为 30 时的训练结果，从下图右下角可以直观的得出，最大正确率为 98.69%，展开后可看到对应的超参值：卷积核大小：5×5&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;code-highlighted code-python&quot;&gt;隐藏层：&lt;span class=&quot;syntax-all syntax-constant&quot;&gt;512&lt;/span&gt;

学习率：&lt;span class=&quot;syntax-all syntax-constant&quot;&gt;0.0008152180302834592&lt;/span&gt;

激活函数：tanh

池化层：最大池化

batch size：&lt;span class=&quot;syntax-all syntax-constant&quot;&gt;32&lt;/span&gt;

dropout rate：&lt;span class=&quot;syntax-all syntax-constant&quot;&gt;0.5&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-234660b64ce9d7cf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;Evolution.png&quot;/&gt;&lt;figcaption&gt;Evolution.png&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-5542875a525bf6fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;Evolution2.png&quot;/&gt;&lt;figcaption&gt;Evolution2.png&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;结果分析：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;正确率前 20% 的 trails 隐藏层多数分布于 512，学习率分布在 0.001 左右较为集中，激活函数为 tanh 较为集中，卷积核大小大部分为 5×5 或 3×3。&lt;/p&gt;

&lt;p&gt;根据以上对结果的分析，可以合理猜测，此模型下设置卷积核大小为 5×5，学习率在 0.001 左右，激活函数选用 tanh，隐藏层为 512，就能获得比较理想的正确率。&lt;/p&gt;

&lt;h3&gt;三、总结&lt;/h3&gt;

&lt;p&gt;综合对比不同 Tuner 的实验结果，发现不同的 Tuner 算法得出的超参分布存在一定差异性，如在使用 Anneal 时准确率前 20% 的 trails 采用的激活函数都为 relu，而 Evolution 的实验中，这部分 trails 却是 tanh 居多。需要思考一下神经网络模型相同的情况下，是什么导致的这些差异性。同样，我们在对比中也能发现许多一致性，通过这些一致性能够对我们的模型调参工作以及对深度学习的理解给予一些启示。&lt;/p&gt;

&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><category term="NNI" /><category term="AutoML" /><category term="工具" /><summary type="html">深度学习自动调参之NNI样例分析 在之前的博文中介绍了 NNI 与其他自动机器学习工具的比较，NNI 的安装和使用等内容，这篇文章你将看到： 如何修改 NNI 官方的 mnist-annotation 例子的配置文件； 官方例子支持的 Tuner 介绍； 各个 Tuner 的训练结果以及结果分析。</summary></entry><entry><title type="html">深度学习自动调参之NNI使用体验</title><link href="http://localhost:4000/nni/2018/12/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%8A%A8%E8%B0%83%E5%8F%82%E4%B9%8BNNI%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/" rel="alternate" type="text/html" title="深度学习自动调参之NNI使用体验" /><published>2018-12-16T00:00:00+08:00</published><updated>2018-12-16T00:00:00+08:00</updated><id>http://localhost:4000/nni/2018/12/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%8A%A8%E8%B0%83%E5%8F%82%E4%B9%8BNNI%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C</id><content type="html" xml:base="http://localhost:4000/nni/2018/12/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%8A%A8%E8%B0%83%E5%8F%82%E4%B9%8BNNI%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/">&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;css/style.css&quot; /&gt;
		&lt;title&gt;深度学习自动调参之NNI使用体验&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-7c9ad7544cf87c62.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot;/&gt;&lt;/figure&gt;
&lt;p&gt;在机器学习建模时，除了准备数据，最耗时耗力的就是尝试各种超参组合，找到模型最佳效果的过程了。即使是对于有经验的算法工程师和数据科学家，有时候也很难把握其中的规律，只能多次尝试，找到较好的超参组合。而对于初学者来说，要花更多的时间和精力。&lt;/p&gt;
&lt;p&gt;自动机器学习这两年成为了热门领域，着力解决超参调试过程的挑战，通过超参选择算法和强大的算力来加速超参搜索的过程。&lt;/p&gt;

&lt;p&gt;NNI (&lt;a href=&quot;https://github.com/microsoft/nni&quot;&gt;Neural Network Intelligence&lt;/a&gt;) 是微软亚洲研究院开源的自动机器学习工具。与当前的各种自动机器学习服务或工具相比，有非常独特的价值。在这篇文章中，你将看到：&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;什么是自动机器学习&lt;/li&gt;
	&lt;li&gt;目前的一些自动机器学习工具&lt;/li&gt;
	&lt;li&gt;关于NNI&lt;/li&gt;
	&lt;li&gt;NNI的安装及使用过程初体验&lt;/li&gt;
	&lt;li&gt;总结NNI可以改进的方面&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;一、关于AutoML&lt;/h2&gt;

&lt;h3&gt;1.1、AutoML出现原因&lt;/h3&gt;

&lt;p&gt;机器学习的应用需要大量的人工干预，这些人工干预表现在：特征提取、模型选择、参数调节等机器学习的各个方面。AutoML视图将这些与特征、模型、优化、评价有关的重要步骤进行自动化地学习，使得机器学习模型无需人工干预即可被应用。&lt;/p&gt;

&lt;h3&gt;1.2、AutoML问题定义&lt;/h3&gt;

&lt;ul&gt;
	&lt;li&gt;从机器学习角度讲，AutoML可以看作是一个在给定数据和任务上学习和泛化能力非常强大的系统。但是它强调必须非常容易使用。&lt;/li&gt;
	&lt;li&gt;从自动化角度讲，AutoML则可以看作是设计一系列高级的控制系统去操作机器学习模型，使得模型可以自动化地学习到合适的参数和配置而无需人工干预。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一个通用的AutoML定义如下：&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-33743c49620333fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot;/&gt;&lt;/figure&gt;

&lt;p&gt;AutoML的核心任务：&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;更好的训练效果&lt;/li&gt;
	&lt;li&gt;没有人为干预&lt;/li&gt;
	&lt;li&gt;更低的计算力需求&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;1.3、AutoML问题构成&lt;/h3&gt;

&lt;p&gt;AutoML的主要问题可以由三部分构成：特征工程、模型选择、算法选择。&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;strong&gt;特征工程&lt;/strong&gt;

		&lt;p&gt;特征工程在机器学习中有着举足轻重的作用。在AutoML中，自动特征工程的目的是自动地发掘并构造相关的特征，使得模型可以有最优的表现。除此之外，还包含一些特定的特征增强方法，例如特征选择、特征降维、特征生成、以及特征编码等。这些步骤目前来说都没有达到自动化的阶段。&lt;/p&gt;

		&lt;p&gt;上述这些步骤也伴随着一定的参数搜索空间。第一种搜索空间是方法自带的，例如PCA自带降维参数需要调整。第二种是特征生成时会将搜索空间扩大。&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;模型选择&lt;/strong&gt;

		&lt;p&gt; 模型选择包括两个步骤：选择一个模型，设定它的参数。相应地，AutoML的目的就是自动选择出一个最合适的模型，并且能够设定好它的最优参数。&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;算法选择&lt;/strong&gt;

		&lt;p&gt;对于算法选择，AutoML 的目的是自动地选择出一个优化算法，以便能够达到效率和精度的平衡。常用的优化方法有 SGD、L-BFGS、GD 等。使用哪个优化算法、对应优化算法的配置，也需要一组搜索空间。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最终从全局来看，我们可以将以上三个关键步骤整合起来看，一个完整的 AutoML 过程可以分成这么两类：一类是将以上的三个步骤整合成一个完整的 pipeline；另一类则是 network architecture search，能够自动地学习到最优的网络结构。在学习的过程中，对以上三个问题都进行一些优化。&lt;/p&gt;

&lt;h3&gt;1.4、基本的优化策略&lt;/h3&gt;

&lt;p&gt;一旦搜索空间确定，我们便可以实用优化器 (optimizer) 进行优化。这里，AutoML 主要回答三个问题： &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;选择的优化器可以作用在哪个搜索空间上？ &lt;/li&gt;
	&lt;li&gt; 它需要什么样的反馈？ &lt;/li&gt;
	&lt;li&gt; 为了取得一个好的效果，它需要怎样的配置？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;简单的优化搜索方式包括 grid search 和 random search。其中 grid search 被广泛使用。&lt;/p&gt;

&lt;p&gt;从样本中进行优化的方法主要包括启发式搜索、derivative-free 优化、以及强化学习方法。梯度下降法是一种重要的优化策略。&lt;/p&gt;

&lt;h3&gt;1.5、评价策略&lt;/h3&gt;

&lt;h4&gt;基本评价策略&lt;/h4&gt;

&lt;p&gt;在设计评价策略时，AutoML主要回答三个问题： &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;这种策略能能够快速进行评价吗？ &lt;/li&gt;
	&lt;li&gt;这种策略能够提供准确的评价吗？&lt;/li&gt;
	&lt;li&gt;这种策略需要怎样的反馈？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;基本的评价策略包括： &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;直接评价。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;直接在目标数据上进行评价。&lt;/strong&gt;这是被使用最多的策略。 &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;采样。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;当数据样本量非常大时，采样一些样本进行评价。&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Early Stop。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当遇到一些极端情况使得网络表现效果不好时，可以考虑进行 Early Stop 来节省资源。 &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;参数重用。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;将之前学习过的参数重复利用在新任务上，以加快训练速度&lt;/strong&gt;。这在两种任务配置差不多时可用。 &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;共轭评价。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于一些可量化的配置，可以用共轭评价法进行。&lt;/p&gt;

&lt;h4&gt;高级评价策略&lt;/h4&gt;

&lt;p&gt;除了上述比较基本的评价策略，我们有时候还会使用更高级评价策略，其主要包括两种：Meta-Learning 和 Transfer Learning。&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;strong&gt;Meta-Learning 法：&lt;/strong&gt;从先前的学习经验中提炼出基本的参数和结构配置。&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Transfer Learning法：&lt;/strong&gt;从先前的学习经验中提炼出可以重用的一些知识。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;1.6、应用&lt;/h3&gt;

&lt;ul&gt;
	&lt;li&gt;使用 Auto-sklearn 进行模型选择。&lt;/li&gt;
	&lt;li&gt;使用强化学习进行 Neural Architecture Search。&lt;/li&gt;
	&lt;li&gt;使用 ExploreKit 进行自动特征构建。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;1.7、展望&lt;/h3&gt;

&lt;p&gt;未来可能的研究方向：&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;提高 AutoML 的效率。&lt;/li&gt;
	&lt;li&gt;更明确的问题定义。&lt;/li&gt;
	&lt;li&gt;发展基本和高级的搜索策略。&lt;/li&gt;
	&lt;li&gt;找到更适合的应用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;二、目前的 AutoML 工具比较&lt;/h2&gt;

&lt;h3&gt;2.1、 TPOT&lt;/h3&gt;

&lt;h4&gt;简介：&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/rhiever/tpot&quot;&gt;TPOT&lt;/a&gt;是一个使用genetic programming算法优化机器学习piplines的Python自动机器学习工具。&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;https://diycode.b0.upaiyun.com/photo/2019/d0593e5ca46fcf2527e4fdc28a369949.gif&quot; alt=&quot;TPOT Demo&quot;/&gt;&lt;figcaption&gt;TPOT Demo&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;TPOT 通过智能地探索数千种可能的 piplines 来为数据找到最好的一个，从而自动化机器学习中最乏味的部分。&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;https://diycode.b0.upaiyun.com/photo/2019/074aedfdefa0ba426daa744f049d87e8.png&quot; alt=&quot;An example Machine Learning pipeline&quot;/&gt;&lt;figcaption&gt;An example Machine Learning pipeline&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;一旦 TPOT 完成了搜索，它就会为用户提供Python代码，以便找到最佳的管道，这样用户就可以从那里修补管道。&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;https://diycode.b0.upaiyun.com/photo/2019/ca3c902881a3f22fd554f5d07006e16c.png&quot; alt=&quot;An example TPOT pipeline&quot;/&gt;&lt;figcaption&gt;An example TPOT pipeline&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h4&gt;输出结果：&lt;/h4&gt;

&lt;p&gt;最佳模型组合及其参数 ( python 文件) 和最佳得分。&lt;/p&gt;

&lt;h4&gt;优劣：&lt;/h4&gt;

&lt;p&gt;TPOT 在数据治理阶段采用了 PCA 主成份分析，在模型选择过程中可以使用组合方法，分析的过程比起其他工具更科学，并能直接生成一个写好参数的python 文件，但输出可参考的结果较少，不利于进一步分析。&lt;/p&gt;

&lt;h3&gt;2.2、Auto_Sklearn&lt;/h3&gt;

&lt;h4&gt;简介：&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;(https://github.com/automl/auto-sklearn)&quot;&gt;Auto-sklearn&lt;/a&gt;将机器学习用户从算法选择和超参数调整中解放出来。它利用了最近在贝叶斯优化、元学习和集成构建方面的优势。&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/1083955-0b02ab1266fec46f.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;img&quot;/&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;主要使用穷举法在有限的时间内逐个尝试最优模型，上图是它的架构体系，看的出来他的工作逻辑是目前的开源框架中最复杂的一款，步骤就不细说了，大体过程应该是与Tpot相似的。&lt;/p&gt;

&lt;h4&gt;输出结果：&lt;/h4&gt;

&lt;p&gt;计算过程以及最终模型的准确率。&lt;/p&gt;

&lt;h4&gt;优劣：&lt;/h4&gt;

&lt;p&gt;穷举法简单粗暴，但也是最靠谱的，如果时间充裕的情况下可以加大预算周期不断让机器尝试最优解，但输出结果太少，基本上对进一步数据分析的帮助不大。&lt;/p&gt;

&lt;h3&gt;2.3、Advisor&lt;/h3&gt;

&lt;figure&gt;&lt;img src=&quot;https://github.com/tobegit3hub/advisor/raw/master/images/advisor_architecture.jpg&quot; alt=&quot;Advisor 框架&quot;/&gt;&lt;figcaption&gt;Advisor 框架&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h4&gt;简介：&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/tobegit3hub/advisor&quot;&gt;Advisor&lt;/a&gt; 是用于黑盒优化的调参系统。它是基于 &lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46180.pdf&quot;&gt;Google Vizier&lt;/a&gt; 的开源实现，编程接口与 Google Vizier 相同。&lt;/p&gt;

&lt;h4&gt;输出结果：&lt;/h4&gt;

&lt;p&gt;推荐参数与训练模型。&lt;/p&gt;

&lt;h4&gt;优劣：&lt;/h4&gt;

&lt;p&gt;方便与 API、SDK、WEB 和 CLI 一起使用，支持研究和试验抽象化，包括搜索和 Early Stop算法，像 Microsoft NNI 一样的命令行工具。&lt;/p&gt;

&lt;p&gt;介绍完以上这些开源的自动机器学习工具，下面一节就要隆重介绍 NNI 了，NNI 对比以上的工具有很多吸引人的优势，同时作为一个刚刚开源的项目，不可避免也存在一些可以改进的方面，让我们开始吧！&lt;/p&gt;

&lt;h2&gt;三、关于NNI&lt;/h2&gt;

&lt;h3&gt;3.1、什么是NNI&lt;/h3&gt;

&lt;p&gt;NNI (Neural Network Intelligence) 是自动机器学习（AutoML）的工具包。 它通过多种调优的算法来搜索最好的神经网络结构和（或）超参，并支持单机、本地多机、云等不同的运行环境。&lt;/p&gt;

&lt;h3&gt;3.2、我们能用NNI做什么？&lt;/h3&gt;

&lt;ul&gt;
	&lt;li&gt;在本地 Trial 不同的自动机器学习算法来训练模型。&lt;/li&gt;
	&lt;li&gt;在分布式环境中加速自动机器学习（如：远程 GPU 工作站和云服务器）。&lt;/li&gt;
	&lt;li&gt;定制自动机器学习算法，或比较不同的自动机器学习算法。&lt;/li&gt;
	&lt;li&gt;在自己的机器学习平台中支持自动机器学习。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;3.3、NNI 安装和使用过程体会&lt;/h3&gt;

&lt;h4&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;NNI 的安装过程非常方便，基本没遇到什么障碍，但需要注意的是，NNI目前只支持 Linux 和 Mac（据说兼容 Win10 版本正在开发中），不过在 Win10上有一个解决方案是可以去应用商店下载一个 Ubuntu 虚拟机，也能很方便的开发。&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-8bebac6b85c7b575.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot;/&gt;&lt;/figure&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/Microsoft/nni/blob/master/zh_CN/docs/Installation.md&quot;&gt;NNI的官方文档&lt;/a&gt;上介绍了三种安装方式，整个过程非常简单，和大部分的开源框架一样，我使用的是第一种：&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;strong&gt;通过 pip 命令安装 NNI&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt; 先决条件：&lt;code&gt;python &amp;gt;= 3.5&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python3 -m pip install --upgrade nni&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;&lt;strong&gt;使用体验&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;将 NNI 从 Github 上 clone 到本地后，进入路径 &lt;code&gt;~/nni/examples/trials/mnist-annotation&lt;/code&gt;，这里是官方提供的 mnist-annotation 例子，能够带你迅速的了解 NNI 的使用。&lt;/p&gt;

&lt;p&gt;将NNI的使用总结一下大体是如下的流程：&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/1083955-b9531d9544428c4a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;流程&quot;/&gt;&lt;figcaption&gt;流程&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
	&lt;li&gt;首先&lt;a href=&quot;https://github.com/Microsoft/nni/blob/master/zh_CN/docs/SearchSpaceSpec.md&quot;&gt;定制搜索空间&lt;/a&gt;（即你提供给NNI一个参数选择范围）&lt;/li&gt;
	&lt;li&gt;命令行启动 NNI ：&lt;code&gt;nnictl create --config ./config.yml&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-d931739210b18365.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;启动nni.PNG&quot;/&gt;&lt;figcaption&gt;启动nni.PNG&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
	&lt;li&gt;在浏览器中打开 &lt;code&gt;Web UI url&lt;/code&gt;，可以看到NNI的可视化界面：&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;&lt;img src=&quot;https://github.com/Microsoft/nni/raw/master/zh_CN/docs/img/webui_overview_page.png&quot; alt=&quot;drawing&quot;/&gt;&lt;figcaption&gt;drawing&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure&gt;&lt;img src=&quot;https://github.com/Microsoft/nni/raw/master/zh_CN/docs/img/webui_trialdetail_page.png&quot; alt=&quot;drawing&quot;/&gt;&lt;figcaption&gt;drawing&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;NNI 的可视化界面也是相较其他工具最讨喜的方面之一，能够让用户在整个实验过程中获得对训练结果的直观理解，方便分析。&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;首页，点击 &lt;code&gt;overview&lt;/code&gt;，可以看到当前试验的进展情况，搜索参数和效果最好的一些超参组合。支持下载 Experiment 结果。&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;&lt;img src=&quot;https://github.com/Microsoft/nni/raw/master/zh_CN/docs/img/webui-img/over1.png&quot; alt=&quot;img&quot;/&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
	&lt;li&gt;查看最好结果的 Trial。&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;&lt;img src=&quot;https://github.com/Microsoft/nni/raw/master/zh_CN/docs/img/webui-img/over2.png&quot; alt=&quot;img&quot;/&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
	&lt;li&gt;通过超参的分布图来直观地看到哪些超参值会明显比较好，或者看出它们之间的关联。通过下面的颜色图就能直观地看到红色（即精度较高的超参组合）线条所表达的丰富信息。如：&lt;/li&gt;
	&lt;li&gt;卷积核大一些会表现较好。&lt;/li&gt;
	&lt;li&gt;全连接层大了不一定太好。也许是所需要的训练时间增加了，训练速度太慢造成的。&lt;/li&gt;
	&lt;li&gt;而学习率小一些（小于0.005），表现基本都不错。&lt;/li&gt;
	&lt;li&gt;ReLU 比 tanh 等其它激活函数也好不少。&lt;/li&gt;
	&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-7abf7e517766a9f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;Hyper Parameter&quot;/&gt;&lt;figcaption&gt;Hyper Parameter&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
	&lt;li&gt;通过试验状态页面，能看到每个试验的时间长度以及具体的超参组合。&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/1083955-971f5a1b145e34ea.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;试验&quot;/&gt;&lt;figcaption&gt;试验&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
	&lt;li&gt;点击 &amp;quot;Trials Detail&amp;quot; 标签查看所有 Trial 的状态。 特别是：&lt;/li&gt;
	&lt;li&gt;Trial 详情：Trial 的 id，持续时间，开始时间，结束时间，状态，精度和搜索空间。

		&lt;figure&gt;&lt;img src=&quot;https://github.com/Microsoft/nni/raw/master/zh_CN/docs/img/webui-img/detail-local.png&quot; alt=&quot;img&quot;/&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt;
	&lt;li&gt;如果在 OpenPAI 或 Kubeflow 平台上运行，还可以看到 hdfsLog。

		&lt;figure&gt;&lt;img src=&quot;https://github.com/Microsoft/nni/raw/master/zh_CN/docs/img/webui-img/detail-pai.png&quot; alt=&quot;img&quot;/&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt;
	&lt;li&gt;Kill: 可终止正在运行的任务。&lt;/li&gt;
	&lt;li&gt;支持搜索某个特定的 Trial。&lt;/li&gt;
	&lt;li&gt;中间结果图。

		&lt;figure&gt;&lt;img src=&quot;https://github.com/Microsoft/nni/raw/master/zh_CN/docs/img/intermediate.png&quot; alt=&quot;img&quot;/&gt;&lt;figcaption&gt;img&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;3.4、NNI的优势&lt;/h3&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;strong&gt;支持私有部署。&lt;/strong&gt;云服务中的自动机器学习直接提供了自动机器学习的服务，不仅包含了自动机器学习的功能，也包含了算力。如果团队或个人已经有了很强的算力资源，就需要支持私有部署的自动学习工具了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt; NNI 支持私有部署。整个部署也很简单，使用 pip 即可完成安装。&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;strong&gt;分布式调度。&lt;/strong&gt;NNI 可以在单机上完成试验，也支持以下两种分布式调度方案：&lt;/li&gt;
	&lt;li&gt;GPU 远程服务器。通过 SSH 控制多台 GPU 服务器协同完成试验，并能够计划每个试验所需要的 GPU 的数量。&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/pai&quot;&gt;OpenPAI&lt;/a&gt;。通过 OpenPAI，NNI 的试验可以在独立的 Docker 中运行，支持多样的实验环境。在计算资源规划上，不仅能指定 GPU 资源，还能制定 CPU，内存资源。&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;超参搜索的直接支持&lt;/strong&gt;。当前，大部分自动机器学习服务与工具都是在某个任务上使用，比如图片分类。这样的好处是，普通用户只要有标记数据，就能训练出一个高质量的平台，不需要任何模型训练方面的知识。但这需要对每个训练任务进行定制，将模型训练的复杂性包装起来。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt; 与大部分现有的自动机器学习服务与工具不同，NNI 需要用户提供训练代码，并指定超参的搜索范围。这样的好处在于，NNI 几乎是通用的工具，任何训练任务都可以使用 NNI 来进行超参搜索。但另一方面，NNI 的通用性，也带来了一定的使用门槛。使用 NNI 需要有基本的模型训练的经验。&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/1083955-ce7d705f7a1ae4ea.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;步骤&quot;/&gt;&lt;figcaption&gt;步骤&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;strong&gt;兼容已有代码。&lt;/strong&gt;NNI 使用时，可以通过注释的方法来进行无侵入式的改动。不会影响代码原先的用途。通过注释方式支持 NNI 后，代码还可以单独运行。&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;易于扩展。&lt;/strong&gt;NNI 的设计上有很强的可扩展性。通过下面这些扩展性，能将系统与算法相隔离，把系统复杂性都包装起来。&lt;/li&gt;
	&lt;li&gt;Tuner 接口，可以轻松实现新的超参调试算法。研究人员可以使用 NNI 来试验新的超参搜索方法，比如在强化学习时，在 Tuner 中支持 off-policy 来探索比较好的超参组合，在 Trial 里进行 on-policy 的实际验证。也可以使用 Tuner 和训练代码相配合，支持复杂的超参搜索方法。如，实现 ENAS ，将 Tuner 作为 Control，在多个 Trial 中并行试验。&lt;/li&gt;
	&lt;li&gt;Accessor 接口，可以加速参数搜索，将表现不好的超参组合提前结束。&lt;/li&gt;
	&lt;li&gt;NNI 还提供了可扩展的集群接口，可以定制对接的计算集群。方便连接已经部署的计算集群。&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;可视化界面。&lt;/strong&gt;在启动一次超参搜索试验后，就可以通过可视化界面来查看试验进展，并帮助超参结果，洞察更多信息。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;四、对NNI的建议&lt;/h2&gt;

&lt;ol&gt;
	&lt;li&gt;拓展web UI的功能：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过控制页面还可以实时的增加试验的超参组合，或者调整超参的范围。&lt;/p&gt;

&lt;p&gt;能够在界面中读取之前的log文件&lt;/p&gt;

&lt;ol start=&quot;2&quot;&gt;
	&lt;li&gt;&lt;strong&gt;中文文档：&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;便于学生使用与查阅，拓展使用群体，降低上手门槛（已解决）&lt;/p&gt;

&lt;ol start=&quot;3&quot;&gt;
	&lt;li&gt;&lt;strong&gt;加入新算法：&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;就在发稿前些天，NNI 支持了较新的 ENAS 算法。看来 DARTS 指日可待。这些 Tuner 算法会在后续的文章中依次介绍的。&lt;/p&gt;

&lt;h2&gt;五、参考资料&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1810.13306&quot;&gt;Taking Human out of Learning Applications: A Survey on Automated Machine Learning&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/48642938&quot;&gt;一篇比较全面的AutoML综述&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/ms-uap/p/9719071.html&quot;&gt;重磅!微软开源自动机器学习工具 - NNI&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://my.oschina.net/knifecms/blog/1606595&quot;&gt;开源自动机器学习(AutoML)框架盘点&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><category term="NNI" /><category term="AutoML" /><category term="工具" /><summary type="html">深度学习自动调参之NNI使用体验 在机器学习建模时，除了准备数据，最耗时耗力的就是尝试各种超参组合，找到模型最佳效果的过程了。即使是对于有经验的算法工程师和数据科学家，有时候也很难把握其中的规律，只能多次尝试，找到较好的超参组合。而对于初学者来说，要花更多的时间和精力。 自动机器学习这两年成为了热门领域，着力解决超参调试过程的挑战，通过超参选择算法和强大的算力来加速超参搜索的过程。</summary></entry><entry><title type="html">微软新工具 NNI 使用指南之 Tuner 篇</title><link href="http://localhost:4000/nni/2018/12/16/%E5%BE%AE%E8%BD%AF%E6%96%B0%E5%B7%A5%E5%85%B7-NNI-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%E4%B9%8B-Tuner-%E7%AF%87/" rel="alternate" type="text/html" title="微软新工具 NNI 使用指南之 Tuner 篇" /><published>2018-12-16T00:00:00+08:00</published><updated>2018-12-16T00:00:00+08:00</updated><id>http://localhost:4000/nni/2018/12/16/%E5%BE%AE%E8%BD%AF%E6%96%B0%E5%B7%A5%E5%85%B7%20NNI%20%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%E4%B9%8B%20Tuner%20%E7%AF%87</id><content type="html" xml:base="http://localhost:4000/nni/2018/12/16/%E5%BE%AE%E8%BD%AF%E6%96%B0%E5%B7%A5%E5%85%B7-NNI-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%E4%B9%8B-Tuner-%E7%AF%87/">&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;css/style.css&quot; /&gt;
		&lt;title&gt;微软新工具 NNI 使用指南之 Tuner 篇&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-7c9ad7544cf87c62.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot;/&gt;&lt;/figure&gt;
&lt;h2&gt;什么是 Tuner&lt;/h2&gt;
&lt;p&gt;在开始之间我们首先需要了解什么是 Tuner。正如之前的博文在 NNI 使用体验中提到的，通俗的来讲，Tuner的作用为让机器自动决定下一次测试的超参设置或下一次尝试的模型结构。 而这篇文章根据学术届的分类将其分为超参调优 (Hyperparameter Optimization)和网络结构搜索 (Neural Architecture Search) 两个部分来介绍。并在每部分结尾处简单介绍一些 NNI 尚未实现但出现在最新顶会中有趣的算法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注：本文中出现的所有引用均可以在该&lt;a href=&quot;https://github.com/VDeamoV/autoML_papers&quot;&gt;仓库&lt;/a&gt; 内找到&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;Hyperparameter Optimization&lt;/h2&gt;

&lt;p&gt;HO(Hyperparameter Optimization) 为超参调优。简单的来说，该算法仅仅是是使用一系列操作针对超参集中选择最优的超参，但未对原有模型结构进行调优。准确的定义如下：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm.&lt;/p&gt;

&lt;p&gt;From Wikipedia&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3&gt;Anneal&lt;/h3&gt;

&lt;p&gt;Anneal Tuner 来源于&lt;a href=&quot;https://www.mathworks.com/help/gads/what-is-simulated-annealing.html&quot;&gt;模拟退火算法&lt;/a&gt; SA(Simulated Annealing)，该算法是一种通用的概率演算法，常用来在一定时间内寻找在一个很大的搜索空间中的近似最优解。该算法类似于贪心算法和遗传算法的结合，其先对上一步中尝试的超参组合进行随机扰动产生新解，之后若该新解有更好的结果则接受新解，若结果变差则按 Metropolis 准则以一定概率接受新解。&lt;/p&gt;

&lt;p&gt;根据 NNI 的 &lt;a href=&quot;https://github.com/Microsoft/nni/blob/master/zh_CN/docs/Builtin_Tuner.md#Anneal&quot;&gt;Anneal 说明文档&lt;/a&gt;，建议在每个 Trial 的时间不长，并且有足够的计算资源，或搜索空间的变量能从一些先验分布中采样的情况下使用，但是结果和 Random Search 相当。&lt;/p&gt;

&lt;h3&gt;Batch Tuner（手动批处理模式）&lt;/h3&gt;

&lt;p&gt;Batch Tuner 的使用场景为，用户只想让 NNI 作为一个批处理工具的场景。该 Tuner 让用&lt;/p&gt;

&lt;p&gt;户自行写入要尝试的超参组合，之后 NNI 会按照设置好的超参组合进行尝试。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;优点：节省手工启动测试程序的步骤&lt;/p&gt;

&lt;p&gt;缺点：NNI 仅作为一个批处理工具&lt;/p&gt;

&lt;p&gt;&lt;em&gt;注：该方法存在的意义在于，可以节省两次调参调整中间的间隔时间&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3&gt;Grid Search&lt;/h3&gt;

&lt;p&gt;网格搜索是一个非常符合人类直观思路的方法，即穷居法。它穷尽了所有种可能的超参排列方式，再依次进行尝试后找到最优方案。过程和我们在中学时学的排列组合一样，三个超参分别有三种取值 3、4、5，那么三种超参就有 3*4*5 = 60 种取值方式。显然这种搜索方式是不科学的，非常容易&lt;strong&gt;组合爆炸&lt;/strong&gt;，是一种非常不高效的调参方式。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;优点：该算法考虑到了搜索空间内所有的参数组合&lt;/p&gt;

&lt;p&gt;缺点：存在组合爆炸的问额&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：强烈不推荐使用&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3&gt;Random Search&lt;/h3&gt;

&lt;p&gt;该思想来源于神经网络三巨头 Bengio 在 JMLR 2012的工作 [1]，这篇论文的核心贡献是从经验和理论上证明了，随机搜索超参的方式相比传统的网格搜索，能在更短的时间内找到一样或更好的模型参数。该算法也从此成为各个优化算法的对比标准。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;优点：容易理解&lt;/p&gt;

&lt;p&gt;缺点：高维搜索空间表现一般&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3&gt;贝叶斯优化系列&lt;/h3&gt;

&lt;p&gt;实际上 Grid Search 和 Random Search 都是非常普通的方法，同时暴力搜索和随机搜索当然也很难体现算法设计者的智慧。而接下来要讲的贝叶斯优化系列则“很可能”存在与人工经验调惨相媲美的实力。&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Bayesian Optimization

		&lt;p&gt;贝叶斯优化 (Bayesian Optimization)，这个工作最初是由 J Snoek et.[2] 在 NIPS 2012 中提出的，并随后多次进行改进 [3, 4]。它要求已经存在几个样本点，并且通过高斯过程回归（&lt;strong&gt;假设超参数间符合联合高斯分布&lt;/strong&gt;）计算前面 n 个点的后验概率分布，得到每一个超参数在每一个取值点的期望均值和方差，其中均值代表这个点最终的期望效果，均值越大表示模型最终指标越大，方差表示这个点的效果不确定性，方差越大表示这个点不确定是否可能取得最大值非常值得去探索，具体的细节分析可以参见这篇&lt;a href=&quot;https://zhuanlan.zhihu.com/p/29779000&quot;&gt;博客&lt;/a&gt;&lt;/p&gt;

		&lt;p&gt;但是这个算法仅仅在低纬空间表现优于 Random Search，而在高维空间和 Random Search 表现相当。&lt;/p&gt;

		&lt;blockquote&gt;
		&lt;p&gt;优点：在低维空间显著优于 Random Search&lt;/p&gt;

		&lt;p&gt;缺点：在高维空间仅和 Random Search 相当&lt;/p&gt;

		&lt;p&gt;&lt;em&gt;注：这个算法的另一个名称为 Spearmint[2]&lt;/em&gt;&lt;/p&gt;
		&lt;/blockquote&gt;&lt;/li&gt;
	&lt;li&gt;TPE

		&lt;p&gt;TPE 算法来源于 Y Bengio 在顶会 NIPS2011 的工作 [7]。 TPE 依旧属于贝叶斯优化，其和 SMAC 也有着很深的渊源。其为一种基于树状结构 Parzen 密度估计的非标准贝叶斯优化算法。相较于其他贝叶斯优化算法，TPE 在高维空间表现最佳。&lt;/p&gt;

		&lt;blockquote&gt;
		&lt;p&gt;优点 1：相比其他贝叶斯优化算法，高维空间的情况下效果更好&lt;/p&gt;

		&lt;p&gt;优点 2：相比 BO 速度有显著提升&lt;/p&gt;

		&lt;p&gt;缺点：在高维空间的情况下，与 Random Search 效果相当&lt;/p&gt;

		&lt;p&gt;&lt;strong&gt;注：所有贝叶斯优化算法在高维空间下表现均和 Random Search 相当 [6]&lt;/strong&gt;&lt;/p&gt;
		&lt;/blockquote&gt;&lt;/li&gt;
	&lt;li&gt;SMAC

		&lt;p&gt;SMAC 算法出自于期刊 LION 2011[5]，其论文中表明，由于先前的 SMBO 算法，不支持离散型变量。SMAC 提出使用 Random Forest 将条件概率 p(y|λ) 建模为高斯分布，其中 λ 为超参的选择。这使得它能够很好的支持离散型变量，并在离散型变量和连续型变量的混合的时候有着不错的表现 [6]。&lt;/p&gt;

		&lt;blockquote&gt;
		&lt;p&gt;优点 1：能很好的支持离散型变量，并针对高维空间有一定改善&lt;/p&gt;

		&lt;p&gt;优点 2：相比 BO 速度有显著提升&lt;/p&gt;

		&lt;p&gt;缺点：效果不稳定，高维空间表现和 Random Search 相当&lt;/p&gt;
		&lt;/blockquote&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;HyperBand&lt;/h3&gt;

&lt;p&gt;HyperBand 来源于非常新的来自 JMLR 2018 的工作 [6]，实质为 &lt;a href=&quot;https://en.wikipedia.org/wiki/Multi-armed_bandit&quot;&gt;Multi-Armed Bandit&lt;/a&gt; 问题。&lt;/p&gt;

&lt;p&gt;其解决的问题为如何平衡“探索”(exploration) 和“利用”(exploitation)。该算法相比之前的算法，最突出的特点为，其限定了资源的总量，优化算法的问题转化为如何在给定资源的情况下，更好的利用资源找出最优解的问题。这些可以体现在超参的设计当中。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;优点 1：考虑到了资源有限的情况&lt;/p&gt;

&lt;p&gt;优点 2：可以和其他的算法，如 TPE 等进行融合（当前 NNI 不支持）[6]&lt;/p&gt;

&lt;p&gt;缺点：算法筛选结果的方式为每多步之后，保留 TopK 的结果，其将导致一些开始收敛较慢的参数配置被淘汰。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3&gt;Metis&lt;/h3&gt;

&lt;p&gt;Metis 为微软提供的自动调参服务，在论文 [8]
中指出，之前的贝叶斯优化算法存在两个较大的问题，一方面贝叶斯优化算法，存在&lt;strong&gt;过度采样&lt;/strong&gt;的问题，这在资源密集型的算法，如深度学习的情况下是一笔很重的开销。另一方面贝叶斯优化和高斯处理算法均假设，问题是&lt;strong&gt;理想的无噪声&lt;/strong&gt;或&lt;strong&gt;仅受高斯分布的噪声影响&lt;/strong&gt;，但实际情况比这个假设要复杂。而 Metis 在一定程度上解决了这个问题。Metis 的本质是随机搜索，为了最小化调整配置时造成的系统性能损失，该算法当且仅当预测的配置可以带来高于一定程度的优化时才会切换配置。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;优点 1：在系统配置选择等存在非高斯噪声的情况下，Metis 显著优于 TPE 算法&lt;/p&gt;

&lt;p&gt;优点 2：能为接下来的尝试提供候选&lt;/p&gt;

&lt;p&gt;缺点：训练时间基本由样本点的数量决定，且呈立方级增长（复杂度为 $O(N^{3}+N^{2}D)$ 其中 N 为样本点数量，D 为样本点的维数）。配置选择时间同样基本由样本点的数目决定，其复杂度为 $O(N^{2}+ND)$ $\Rightarrow$ 和样本点的数据量高度相关且复杂度高&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：NNI 中 Metis 只支持 &lt;code&gt;choice&lt;/code&gt;, &lt;code&gt;quniform&lt;/code&gt;, &lt;code&gt;uniform&lt;/code&gt; 和 &lt;code&gt;randint&lt;/code&gt; 类型。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;Neural Architecture Search&lt;/h2&gt;

&lt;h3&gt;什么是 NAS&lt;/h3&gt;

&lt;p&gt;和上一节中的 HO 不同的是，在超参调整中，NAS 调整的超参会影响到模型的结构。意在通过大量尝试探索一种更为合理的网络结构。而这些超参的调整已经超出了之前介绍的贝叶斯优化系列的能力范畴。在 NAS 中遗传算法系列和强化学习系列有着不错的表现。&lt;/p&gt;

&lt;h3&gt;Naive Evolution&lt;/h3&gt;

&lt;p&gt;Naive Evolution 出自 ICML 2017 的工作 [9]，其将遗传算法引入模型结构的搜索。根据论文中的描述，该方法为一种典型的&lt;a href=&quot;https://zh.wikipedia.org/zh-hans/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95)&quot;&gt;遗传算法&lt;/a&gt;，其通过设置一定量的初始种群，经过“突变”（更改超参）后根据“自然筛选”（筛选出表现优秀的模型）保留优异的个体。论文中是针对图片分类的模型探索，支持多种“突变”，细节可参见原论文 [9]。除了使用遗传算法这个特点外，其还有一个特点是支持&lt;strong&gt;权重迁移&lt;/strong&gt;的模型，这个特点会使得每个突变个体只需要少量的 epoch 来训练。而这个优点也在 Morphism 算法中得以体现。但是该算法也存在陷入局部最优解的问题，论文中描述该问题主要可以通过增大以下两个参数解决。&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;population size

		&lt;p&gt;这个参数的增大会让初始种群个体数量更多，这样子可以通过增加会避免模型陷入局部最优解。&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;the number of training steps per individual

		&lt;p&gt;这个参数的增大会让每一个个体的表现得到最大的发挥，从而不会错淘汰掉潜力优秀的个体&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;注：遗憾的是 NNI 中还未能让用户自行调整这两个参数&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;优点 1: 使用遗传算法进行模型结构的搜索&lt;/p&gt;

&lt;p&gt;优点 2: 对支持权重迁移的模型，运算的速度会有显著提升&lt;/p&gt;

&lt;p&gt;缺点：同所有的遗传算法一样，优于需要尝试大量的突变个体，需要大量的计算资源&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3&gt;Network Morphism&lt;/h3&gt;

&lt;p&gt;Network Morphism 来自另一个开源自动调参工具 &lt;a href=&quot;https://autokeras.com&quot;&gt;Auto-keras&lt;/a&gt; 的其中一篇 arXiv 上的文章 [10]。该算法的设计的初衷是减少调参的计算损耗。为了提高算法的效率，其引入了一个新的神经网络核 (Neural Network Kernel) 和 一个树形采样函数，来用贝叶斯优化的方式探索搜索空间。&lt;/p&gt;

&lt;p&gt;除此之外，另一点提高效率的方式为引入了 Morphism Operation。该操作是在已经训练好的模型上进行调整，这样新生成的网络结构就只需要少量的训练就能达到好的效果。这个方式在 Naive Evolution 也有使用。就论文中在 MNIST，FASHION，CIFAR-10 三个数据集上的实验结果看，其显著好于 Random Search，SPMT[11]，SMAC，SEA[12]，NASBOT[13]。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;优点 1: 在探索网络结构的时候引入了贝叶斯优化，提高了搜索效率&lt;/p&gt;

&lt;p&gt;优点 2: Morphism 操作，保留了之前的训练的结果，让新的变种网络训练的更快&lt;/p&gt;

&lt;p&gt;缺点：当前版本不支持 RNN 的网络模型探索&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3&gt;ENAS&lt;/h3&gt;

&lt;p&gt;ENAS 源自 CVPR 2018 的一个工作 [14]，其使用 RNN 作为控制器然后根据收敛精度调整 RNN，&lt;/p&gt;

&lt;p&gt;论文中在 Cifar10 上训练 RNN，之后再应用到 ImageNet 上，效果很惊人（应用到 Fast-RCNN 上之后居然有 4% 的准确率提升）。但是该算法&lt;strong&gt;需要很多预先的人为的前提设定&lt;/strong&gt;，同时&lt;strong&gt;速度还是很慢&lt;/strong&gt;, 而 ENAS 的主要工作为在其工作上，增加参数共享的方式，避免新产生的模型重训练，加快了训练速度。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;优点：相较于其他的 NAS 算法，该算法速度非常快&lt;/p&gt;

&lt;p&gt;缺点：同它的改进的模型一样，其需要设置每个 Cell 的 Block 等多个前提设定的参数&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：相较于其他算法，这个算法更有趣，论文中的效果现实也是最有意思最好的&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;NNI 未实现但很有趣的算法&lt;/h2&gt;

&lt;h3&gt;NASBOT&lt;/h3&gt;

&lt;p&gt;NASBOT 源自 NIPS2018 的一个工作 [13]， 其核心就在于计算 OTMANN distance。该方法使用了 layer masses 和 path length 来定义 OTMANN distance。&lt;/p&gt;

&lt;p&gt;三者的定义如下：&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;layer masses：在比较两个神经网络时匹配的层的个数&lt;/li&gt;
	&lt;li&gt;path length：两个层之前的距离，如 (2, 5, 8, 13) 是一条从 layer2 到 layer13 的一条长度为 3 的路径&lt;/li&gt;
	&lt;li&gt;OTMANN distance：通过最优化算法得出的神经网络之间的距离&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;就结果而言论文中表明 NASBOT 在 Cifar10 数据集上，在&lt;strong&gt;计算量&lt;/strong&gt;和&lt;strong&gt;运行时间&lt;/strong&gt;方面显著优于其他 tuner 算法，如随机搜索，进化算法等。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;优点 1：对 MLPs 和 CNN 的支持效果较好&lt;/p&gt;

&lt;p&gt;优点 2：训练需要的总计算量较小&lt;/p&gt;

&lt;p&gt;缺点：在寻找下一个网络架构的用时较长&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;注：该算法的 python 实现：&lt;a href=&quot;https://github.com/kirthevasank/nasbot&quot;&gt;源码链接&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3&gt;DARTS&lt;/h3&gt;

&lt;p&gt;DARTS 为在 arXiv 上的一篇很有意思的工作 [15]，其正在等待 ICLR 2019 的审核，详情可以参见 OpenReview 该&lt;a href=&quot;https://openreview.net/forum?id=S1eYHoC5FX&quot;&gt;论文的链接&lt;/a&gt;。该工作的中心思想为&lt;strong&gt;科学选择神经网络结构，将神经网络结构作为参数进行优化&lt;/strong&gt;。该论文在 Cifar10，ImageNet 等数据集上进行了大量的实验，发现此算法适用于图像分类的高性能卷积结构和语言建模的循环神经网络结构，并提出此方法的&lt;strong&gt;效率高于 ENAS&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;优点 1：将模型结构视为参数，扩大搜索空间&lt;/p&gt;

&lt;p&gt;优点 2：较高的可迁移性&lt;/p&gt;

&lt;p&gt;缺点：参数过多，对算力和数据量的要求较高 &lt;/p&gt;

&lt;p&gt;注：该论文的复现可以参考作者的源码：&lt;a href=&quot;https://github.com/quark0/darts&quot;&gt;源码链接&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;参考论文&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;[1] Bergstra J, Bengio Y. Random search for hyper-parameter optimization[J]. Journal of Machine Learning Research, 2012, 13(Feb): 281-305.&lt;/li&gt;
	&lt;li&gt;[2] Snoek J, Larochelle H, Adams R P. Practical bayesian optimization of machine learning algorithms[C]//Advances in neural information processing systems. 2012: 2951-2959.&lt;/li&gt;
	&lt;li&gt;[3] Swersky K, Snoek J, Adams R P. Multi-task bayesian optimization[C]//Advances in neural information processing systems. 2013: 2004-2012.&lt;/li&gt;
	&lt;li&gt;[4] Snoek J, Rippel O, Swersky K, et al. Scalable bayesian optimization using deep neural networks[C]//International Conference on Machine Learning. 2015: 2171-2180.&lt;/li&gt;
	&lt;li&gt;[5] Hutter F, Hoos H H, Leyton-Brown K. Sequential model-based optimization for general algorithm configuration[C]//International Conference on Learning and Intelligent Optimization. Springer, Berlin, Heidelberg, 2011: 507-523.&lt;/li&gt;
	&lt;li&gt;[6] Li L, Jamieson K, DeSalvo G, et al. Hyperband: A novel bandit-based approach to hyperparameter optimization[J]. arXiv preprint arXiv:1603.06560, 2018: 1-48.&lt;/li&gt;
	&lt;li&gt;[7] Bergstra J S, Bardenet R, Bengio Y, et al. Algorithms for hyper-parameter optimization[C]//Advances in neural information processing systems. 2011: 2546-2554.&lt;/li&gt;
	&lt;li&gt;[8] Li Z L, Liang C J M, He W, et al. Metis: robustly optimizing tail latencies of cloud systems[C]//Proceedings of the 2018 USENIX Conference on Usenix Annual Technical Conference. USENIX Association, 2018: 981-992.&lt;/li&gt;
	&lt;li&gt;[9] Real, E., Moore, S., Selle, A., Saxena, S., Suematsu, Y. L., Tan, J., ... &amp;amp; Kurakin, A. (2017, July). Large-Scale Evolution of Image Classifiers. In International Conference on Machine Learning (pp. 2902-2911).&lt;/li&gt;
	&lt;li&gt;[10] Jin H, Song Q, Hu X. Efficient neural architecture search with network morphism[J]. arXiv preprint arXiv:1806.10282, 2018.&lt;/li&gt;
	&lt;li&gt;[11] Snoek, J., Larochelle, H., and Adams, R. P.Practical bayesian optimization of machine learning algorithms.In Advances in Neural Information Processing Systems, pp. 2951–2959, 2012.&lt;/li&gt;
	&lt;li&gt;[12] Elsken, T., Metzen, J. H., and Hutter, F. Neural architec- ture search: A survey. arXiv preprint arXiv:1808.05377, 2018.&lt;/li&gt;
	&lt;li&gt;[13] Kandasamy, K., Neiswanger, W., Schneider, J., Poczos, B., and Xing, E. Neural architecture search with bayesian optimisation and optimal transport. NIPS, 2018.&lt;/li&gt;
	&lt;li&gt;[14] Zoph B, Vasudevan V, Shlens J, et al. Learning transferable architectures for scalable image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 8697-8710.&lt;/li&gt;
	&lt;li&gt;[15] Liu, Hanxiao, Karen Simonyan, and Yiming Yang. Darts: Differentiable architecture search. arXiv preprint arXiv:1806.09055 (2018).&lt;/li&gt;
&lt;/ul&gt;

&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><category term="NNI" /><category term="AutoML" /><category term="工具" /><summary type="html">微软新工具 NNI 使用指南之 Tuner 篇 什么是 Tuner 在开始之间我们首先需要了解什么是 Tuner。正如之前的博文在 NNI 使用体验中提到的，通俗的来讲，Tuner的作用为让机器自动决定下一次测试的超参设置或下一次尝试的模型结构。 而这篇文章根据学术届的分类将其分为超参调优 (Hyperparameter Optimization)和网络结构搜索 (Neural Architecture Search) 两个部分来介绍。并在每部分结尾处简单介绍一些 NNI 尚未实现但出现在最新顶会中有趣的算法。 注：本文中出现的所有引用均可以在该仓库 内找到</summary></entry><entry><title type="html">微软新工具 NNI 使用指南之 Assessor 篇</title><link href="http://localhost:4000/nni/2018/12/16/%E5%BE%AE%E8%BD%AF%E6%96%B0%E5%B7%A5%E5%85%B7-NNI-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%E4%B9%8B-Assessor-%E7%AF%87/" rel="alternate" type="text/html" title="微软新工具 NNI 使用指南之 Assessor 篇" /><published>2018-12-16T00:00:00+08:00</published><updated>2018-12-16T00:00:00+08:00</updated><id>http://localhost:4000/nni/2018/12/16/%E5%BE%AE%E8%BD%AF%E6%96%B0%E5%B7%A5%E5%85%B7%20NNI%20%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%E4%B9%8B%20Assessor%20%E7%AF%87</id><content type="html" xml:base="http://localhost:4000/nni/2018/12/16/%E5%BE%AE%E8%BD%AF%E6%96%B0%E5%B7%A5%E5%85%B7-NNI-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%E4%B9%8B-Assessor-%E7%AF%87/">&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;css/style.css&quot; /&gt;
		&lt;title&gt;微软新工具 NNI 使用指南之 Assessor 篇&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;figure&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1083955-7c9ad7544cf87c62.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot;/&gt;&lt;/figure&gt;
&lt;h2&gt;什么是 Assessor&lt;/h2&gt;
&lt;p&gt;在说 NNI 中的 Assessor 算法前，首先需要了解下什么是 Assessor。通常来说，“Assessor” 不是论文中的通常叫法，一般而言 Assessor 在论文中被叫做 “Early Stop”。顾名思义，该模块的作用在于判断当前尝试的超参是否有“前途”，如果当前设置被判断为即便多次迭代后仍无法获得更好的结果时便提前终止迭代，以节约宝贵的计算资源。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注：本文中出现的所有引用均可以在该&lt;a href=&quot;https://github.com/VDeamoV/autoML_papers&quot;&gt;仓库&lt;/a&gt; 内找到&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;NNI 已有 Assessor 算法介绍&lt;/h2&gt;

&lt;h3&gt;Median Stop&lt;/h3&gt;

&lt;p&gt;Median Stop 出现在 Goolge 的自动调参工具的论文 [1] 中，该方法在论文中的描述为，在当前尝试的超参训练的过程中，如果出现最新 step 的结果比之前所有的 step 的结果的均值要低的情况，则终止该训练。这种方法的优点为&lt;strong&gt;不需要拟合曲线，运算简单&lt;/strong&gt;，但是缺点也很明显，即利用之前步骤的信息较少，判断可能不是很准确。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;优点：算法简单，算法运算速度快&lt;br&gt;&lt;/p&gt;

&lt;p&gt;缺点：对之前已有的信息利用不充分，判断结果相对较不准确，如曲线震荡幅度比较大但是最终结果很好的情况。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3&gt;Curvefitting&lt;/h3&gt;

&lt;p&gt;Curvefitting 是一篇在顶会 IJCAI 的工作 [2]，相比之前的 Median Stop 算法，该算法同贝叶斯优化算法类似，使用之前的 n 个样本点来拟合学习曲线。而与传统的使用高斯处理来拟合学习曲线不同的是，该算法引入了马尔可夫蒙特卡洛 (Markov Chain Monte Carlo)，这使得算法能够更加充分利用之前的样本点中的信息，以更好的预测当前训练的最终结果。该算法的停止标准为，&lt;strong&gt;当预计当前算法的最优结果低于之前的最优结果&lt;/strong&gt;，则决定提前停止当前尝试。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;优点：能够更好的学习到前几次的尝试样本，能更准确的判断是否该提前停止&lt;br&gt;&lt;/p&gt;

&lt;p&gt;缺点：该算法需要冷启动，需要设置较多超参&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;论文中的实验将 Curvefitting 同 SMAC 结合，如图 2.1 所示，可以看出效果还是非常明显的。&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;https://ws4.sinaimg.cn/large/006tNc79ly1g02mxvl23pj31uo0oin1x.jpg&quot; alt=&quot;图 2.1 Curvefitting&quot;/&gt;&lt;figcaption&gt;图 2.1 Curvefitting&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2&gt;结语&lt;/h2&gt;

&lt;p&gt;当前已有的 Assessor 主要出自 Google 的 Google Vizier[3]，经过对论文的调查有效的 Early Stop 算法均以实现。 当前 NNI 内的 Assessor 的定义有些类似 Early Stop，而这个单独作为一类的话似乎有点太奢侈。在 Tuner 的调研中，发现有一些算法，如 Hyperband[4] 是可以和其他 Tuner 进行融合而具有更好的结果的。如果将 Assessor 定义为可以和基础算法进行融合的算法的话，似乎可以让 Tuner 的配置更具灵活性。&lt;/p&gt;

&lt;p&gt;但是不管怎么说，Assessor 的使用简单明确，对新手非常友好是一个很好的组件。NNI 也是一个简单易用的工具，希望未来 NNI 越来越完善，最终成为炼丹师们的好帮手。&lt;/p&gt;

&lt;h2&gt;参考论文&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;[1] Golovin D, Solnik B, Moitra S, et al. Google vizier: A service for black-box optimization[C]//Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2017: 1487-1495.&lt;/li&gt;
	&lt;li&gt;[2] Domhan T, Springenberg J T, Hutter F. Speeding Up Automatic Hyperparameter Optimization of Deep Neural Networks by Extrapolation of Learning Curves[C]//IJCAI. 2015, 15: 3460-8.&lt;/li&gt;
	&lt;li&gt;[3] Golovin D, Solnik B, Moitra S, et al. Google vizier: A service for black-box optimization[C]//Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2017: 1487-1495.&lt;/li&gt;
	&lt;li&gt;[4] Li L, Jamieson K, DeSalvo G, et al. Hyperband: A novel bandit-based approach to hyperparameter optimization[J]. arXiv preprint arXiv:1603.06560, 2018: 1-48.&lt;/li&gt;
&lt;/ul&gt;

&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><category term="NNI" /><category term="AutoML" /><category term="工具" /><summary type="html">微软新工具 NNI 使用指南之 Assessor 篇 什么是 Assessor 在说 NNI 中的 Assessor 算法前，首先需要了解下什么是 Assessor。通常来说，“Assessor” 不是论文中的通常叫法，一般而言 Assessor 在论文中被叫做 “Early Stop”。顾名思义，该模块的作用在于判断当前尝试的超参是否有“前途”，如果当前设置被判断为即便多次迭代后仍无法获得更好的结果时便提前终止迭代，以节约宝贵的计算资源。 注：本文中出现的所有引用均可以在该仓库 内找到</summary></entry><entry><title type="html">Tensorflow进阶之数据导入</title><link href="http://localhost:4000/tensorflow/2018/12/16/Tensorflow%E8%BF%9B%E9%98%B6%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/" rel="alternate" type="text/html" title="Tensorflow进阶之数据导入" /><published>2018-12-16T00:00:00+08:00</published><updated>2018-12-16T00:00:00+08:00</updated><id>http://localhost:4000/tensorflow/2018/12/16/Tensorflow%E8%BF%9B%E9%98%B6%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5</id><content type="html" xml:base="http://localhost:4000/tensorflow/2018/12/16/Tensorflow%E8%BF%9B%E9%98%B6%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/">&lt;h2 id=&quot;不同格式的数据的导入&quot;&gt;不同格式的数据的导入&lt;/h2&gt;
&lt;h3 id=&quot;numpy-数据的导入&quot;&gt;Numpy 数据的导入&lt;/h3&gt;
&lt;p&gt;这种导入非常直白，就是使用 Numpy 把外部的数据进行导入，然后转换成 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.Tensor&lt;/code&gt; ，之后使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;Dataset.from_tensor_slices()&lt;/code&gt;。就可以成功导入了。简单的案例如下：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Load&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;two&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NumPy&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arrays&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/var/data/training_data.npy&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;data:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;features&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;labels&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Assume&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;that&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;`&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;corresponds&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;same&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;from_tensor_slices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;上面的简单的实例有一个很大的问题，就是 &lt;code class=&quot;highlighter-rouge&quot;&gt;features&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;labels&lt;/code&gt; 会作为 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.constant()&lt;/code&gt; 指令嵌入在 Tensorflow 的图中，会浪费很多内存。所以我们可以根据 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.palceholder()&lt;/code&gt; 来定义 &lt;code class=&quot;highlighter-rouge&quot;&gt;Dataset&lt;/code&gt;，同时在对数据集初始化的时候送入 Numpy 数组。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/var/data/training_data.npy&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;data:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;features&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;labels&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Assume&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;that&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;`&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;corresponds&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;same&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;features_placeholder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;labels_placeholder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;from_tensor_slices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features_placeholder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels_placeholder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Other&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformations&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;make_initializable_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;features_placeholder:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
                                          &lt;span class=&quot;nl&quot;&gt;labels_placeholder:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h3 id=&quot;tfrecord-数据的导入&quot;&gt;TFRecord 数据的导入&lt;/h3&gt;
&lt;p&gt;TFRecord 是一种面向记录的简单二进制格式，很多 Tensorflow 应用采用这种方式来训练数据。这个也是推荐的做法。将它做成 Dataset 的方式也非常简单，就是单纯的通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.data.TFRecordDataset&lt;/code&gt; 类就可以实现。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Creates&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;that&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reads&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;examples&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;two&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/var/data/file1.tfrecord&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/var/data/file2.tfrecord&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;TFRecordDataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;同样我们也能设定成，在初始化迭代器的时候导入数据。其中需要注意的是 &lt;code class=&quot;highlighter-rouge&quot;&gt;filenames&lt;/code&gt; 需要设置成 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.String&lt;/code&gt; 类。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;TFRecordDataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(...)&lt;/span&gt;  &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parse&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;repeat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Repeat&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indefinitely&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;make_initializable_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;You&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;can&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initializer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;appropriate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;execution&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Initialize&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;`&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;training_filenames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/var/data/file1.tfrecord&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/var/data/file2.tfrecord&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;filenames:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training_filenames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Initialize&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;`&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;validation_filenames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/var/data/validation1.tfrecord&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;filenames:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_filenames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h2 id=&quot;dataset-的预处理&quot;&gt;Dataset 的预处理&lt;/h2&gt;
&lt;h3 id=&quot;datasetmap&quot;&gt;Dataset.map()&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Dataset.map(f)&lt;/code&gt; 转换通过将指定函数 &lt;code class=&quot;highlighter-rouge&quot;&gt;f&lt;/code&gt; 应用于输入数据集的每个元素来生成新数据集。
简单的实例（解码图片数据并调整大小）如下：&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Reads&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;an&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decodes&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dense&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resizes&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fixed&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_parse_function&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;image_string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;image_decoded&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;decode_jpeg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;image_resized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;resize_images&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_decoded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_resized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;constant&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/var/data/image1.jpg&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/var/data/image2.jpg&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...])&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;`&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;].&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;constant&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;from_tensor_slices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_parse_function&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;至此为止，我们对图片的处理还是使用的是 TensorFlow 中的 API，那么我们想用 Python 自带的奇奇怪怪的包应该怎么做呢。TensorFlow 给了我们 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.py_func()&lt;/code&gt; 这个选项来使用任意 Python 逻辑。我们只用在 &lt;code class=&quot;highlighter-rouge&quot;&gt;Dataset.map()&lt;/code&gt; 中调用 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.py_func()&lt;/code&gt; 指令就可以了。简单的例子如下：&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;cv2&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Use&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;custom&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OpenCV&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instead&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;standard&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TensorFlow&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;`&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;operation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_read_py_function&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;image_decoded&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;imread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;IMREAD_GRAYSCALE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_decoded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Use&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;standard&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TensorFlow&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;operations&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fixed&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_resize_function&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_decoded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;image_decoded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;set_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;image_resized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;resize_images&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_decoded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_resized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/var/data/image1.jpg&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/var/data/image2.jpg&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;29&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;from_tensor_slices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;label:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;py_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;_read_py_function&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;uint8&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_resize_function&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h3 id=&quot;批处理数据&quot;&gt;批处理数据&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;简单的批处理
 简单的批处理我们直接调用 &lt;code class=&quot;highlighter-rouge&quot;&gt;Dataset.batch()&lt;/code&gt; 这种 API 即可，但是它有一个限制就是对于每个组件 i，所有元素的&lt;strong&gt;张量形状都必须完全相同&lt;/strong&gt;。
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; inc_dataset = tf.data.Dataset.range(100)
 dec_dataset = tf.data.Dataset.range(0, -100, -1)
 dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))
 batched_dataset = dataset.batch(4)

 iterator = batched_dataset.make_one_shot_iterator()
 next_element = iterator.get_next()

 print(sess.run(next_element))  # ==&amp;gt; ([0, 1, 2,   3],   [ 0, -1,  -2,  -3])
 print(sess.run(next_element))  # ==&amp;gt; ([4, 5, 6,   7],   [-4, -5,  -6,  -7])
 print(sess.run(next_element))  # ==&amp;gt; ([8, 9, 10, 11],   [-8, -9, -10, -11])
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;填充批处理张量
 和简单批处理相比，这种方式可以对具有不同大小的张量进行批处理。这种方法的 API 为 &lt;code class=&quot;highlighter-rouge&quot;&gt;Dataset.padded_batch()&lt;/code&gt;。简单的实例展示如下：
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padded_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padded_shapes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

 &lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make_one_shot_iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;next_element&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_element&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# ==&amp;gt; [[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]]&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_element&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# ==&amp;gt; [[4, 4, 4, 4, 0, 0, 0],&lt;/span&gt;
                         	   &lt;span class=&quot;c&quot;&gt;#      [5, 5, 5, 5, 5, 0, 0],&lt;/span&gt;
                         	   &lt;span class=&quot;c&quot;&gt;#      [6, 6, 6, 6, 6, 6, 0],&lt;/span&gt;
                         	   &lt;span class=&quot;c&quot;&gt;#      [7, 7, 7, 7, 7, 7, 7]]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;可以通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;Dataset.padded_batch()&lt;/code&gt; 转换为每个组件的每个维度设置不同的填充，并且可以采用可变长度（在上面的示例中用 &lt;code class=&quot;highlighter-rouge&quot;&gt;None&lt;/code&gt; 表示）或恒定长度。也可以替换填充值，默认设置为 0。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;训练工作流程&quot;&gt;训练工作流程&lt;/h2&gt;
&lt;h3 id=&quot;处理多个周期&quot;&gt;处理多个周期&lt;/h3&gt;
&lt;p&gt;有时候我们希望我们的数据集能训练很多个周期，简单的方法是使用&lt;code class=&quot;highlighter-rouge&quot;&gt;Dataset.repeat()&lt;/code&gt; API。&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/var/data/file1.tfrecord&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/var/data/file2.tfrecord&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TFRecordDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;repeat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;上述例子中，我们将 dataset 重复了 10 个周期，值得注意的是如果 repeat 中没有参数代表中无限次地重复使用，即不会在一个周期结束和下一个周期开始时发出信号。&lt;/p&gt;

&lt;p&gt;如果我们想在每个周期结束时收到信号，则可以编写在数据集结束时捕获 &lt;a href=&quot;https://tensorflow.google.cn/api_docs/python/tf/errors/OutOfRangeError?hl=zh-cn&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.errors.OutOfRangeError&lt;/code&gt;&lt;/a&gt; 的训练循环。此时，就可以收集关于该周期的一些统计信息。&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/var/data/file1.tfrecord&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/var/data/file2.tfrecord&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TFRecordDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make_initializable_iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;next_element&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Compute for 100 epochs.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_element&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OutOfRangeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# [Perform end-of-epoch calculations here.]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h3 id=&quot;随机重排数据&quot;&gt;随机重排数据&lt;/h3&gt;
&lt;p&gt;有时候我们希望能随机的选取 Dataset 中的元素，则可以使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;Dataset.shuffle()&lt;/code&gt;。&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/var/data/file1.tfrecord&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/var/data/file2.tfrecord&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TFRecordDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buffer_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;repeat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://tensorflow.google.cn/guide/datasets?hl=zh-cn&quot;&gt;[官方教程]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>DeamoV</name></author><category term="TensorFlow" /><category term="Dataset" /><summary type="html">不同格式的数据的导入 Numpy 数据的导入 这种导入非常直白，就是使用 Numpy 把外部的数据进行导入，然后转换成 tf.Tensor ，之后使用 Dataset.from_tensor_slices()。就可以成功导入了。简单的案例如下：</summary></entry><entry><title type="html">python数据可视化之 seaborn</title><link href="http://localhost:4000/python/2018/12/11/python%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B9%8Bseaborn/" rel="alternate" type="text/html" title="python数据可视化之 seaborn" /><published>2018-12-11T00:00:00+08:00</published><updated>2018-12-11T00:00:00+08:00</updated><id>http://localhost:4000/python/2018/12/11/python%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B9%8Bseaborn</id><content type="html" xml:base="http://localhost:4000/python/2018/12/11/python%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B9%8Bseaborn/">&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;Seaborn 是一个数据可视化的库，主要用来生成热力图的，详情查看它的&lt;a href=&quot;http://seaborn.pydata.org/tutorial.html&quot;&gt;官网&lt;/a&gt;。这个工具一定要混合 &lt;code class=&quot;highlighter-rouge&quot;&gt;matplotlib&lt;/code&gt; 来使用，我们在做好图之后还是必须要用 &lt;code class=&quot;highlighter-rouge&quot;&gt;plt.show&lt;/code&gt; 才能展示图片，同时图片的布局也是靠 &lt;code class=&quot;highlighter-rouge&quot;&gt;matplotlib&lt;/code&gt;。&lt;/p&gt;

&lt;h2 id=&quot;热力图&quot;&gt;热力图&lt;/h2&gt;
&lt;p&gt;热力图很多人其实是第一次接触，我在查了百度之后的百度百科结果不太满意，转而投奔&lt;a href=&quot;https://en.wikipedia.org/wiki/Heat_map&quot;&gt; Wiki 结果&lt;/a&gt;如下：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;A heat map (or heatmap) is a graphical representation of data where the individual values contained in a matrix are represented as colors. “Heat map” is a newer term but shading matrices have existed for over a century.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;除此之外我们还可以看到一些重要的描述如下：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Heat maps originated in 2D displays of the values in a data matrix. Larger values were represented by small dark gray or black squares (pixels) and smaller values by lighter squares.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们可以看到它其实是用深浅来表示大小的。调用 seaborn 的代码实现如下：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;seaborn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sns&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;uniform_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heatmap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uniform_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://ws1.sinaimg.cn/large/006tNbRwly1fy2vqxl9mtj30zm0tqglu.jpg&quot; alt=&quot;&quot; /&gt;
当然这仅仅是热图中的一小部分，它还有其他功能，可以参考&lt;a href=&quot;http://seaborn.pydata.org/generated/seaborn.heatmap.html?highlight=heatmap#seaborn.heatmap&quot;&gt;官网 heatmap 的章节&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;密度图&quot;&gt;密度图&lt;/h2&gt;
&lt;p&gt;通过这个图我们能看出数据的密度，能很直观的看出输出的值最集中的区域。简单的代码（二维密度图）如下：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;seaborn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color_codes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multivariate_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kdeplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://ws4.sinaimg.cn/large/006tNbRwly1fy2vqz5xrkj30zi0ty0t1.jpg&quot; alt=&quot;&quot; /&gt;
同理，其他细节可以参考&lt;a href=&quot;http://seaborn.pydata.org/generated/seaborn.kdeplot.html?highlight=kdeplot#seaborn.kdeplot&quot;&gt;官网 kdeplot 章节&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;结尾&quot;&gt;结尾&lt;/h2&gt;
&lt;p&gt;对于可视化的工具，个人比较喜欢插它官网的 Gallery，比如 Echart 的 Gallery，在 Gallery 中我们可以很好的把握图标的样式，还能得到样例代码，不失为一件美事。&lt;/p&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/M7wC0XhDtenvTA_y1jfSjQ&quot; title=&quot;机器之心&quot;&gt;4种更快更简单实现 Python 数据可视化的方法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://seaborn.pydata.org/examples/index.html&quot;&gt;seaborn 官网 Gallery&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>DeamoV</name></author><category term="Python" /><category term="技巧" /><summary type="html">简介 Seaborn 是一个数据可视化的库，主要用来生成热力图的，详情查看它的官网。这个工具一定要混合 matplotlib 来使用，我们在做好图之后还是必须要用 plt.show 才能展示图片，同时图片的布局也是靠 matplotlib。</summary></entry></feed>